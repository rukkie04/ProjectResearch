{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAME: RUKAYAT ADEOSUN\n",
    "\n",
    "TITLE: HEIRARCHICAL CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster import hierarchy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data set\n",
    "df = pd.read_excel('/Users/rukayatadeosun/Downloads/data1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a new column to indicate presence/absence of response\n",
    "new_label = [] \n",
    "for value in df[\"response\"]: \n",
    "    if value <= 0: \n",
    "        new_label.append(\"__NORES\")\n",
    "    else: \n",
    "        new_label.append(\"__RES\")\n",
    "       \n",
    "df[\"New_label\"] = new_label   \n",
    "pd.set_option('display.max_columns', 500,'display.max_rows', 500)\n",
    "\n",
    "#print(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the columns in the dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column ID (New_ID) to label HC by concatenating columns ID and New label\n",
    "df['New_ID'] = df[['ID', 'New_label']].apply(lambda x: ''.join(x), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the label column\n",
    "df['New_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the new column \n",
    "df['New_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To drop string labels \n",
    "del df['ID']\n",
    "del df['response']\n",
    "del df['New_label']\n",
    "\n",
    "# To drop some unimportant columns \n",
    "del df['Echo_pre_LVEF']\n",
    "del df['height']\n",
    "del df['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To set the column new ID as index \n",
    "df1 = df.set_index('New_ID', inplace=False)\n",
    "print(df1.shape)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the count and percentage of categorical variables in the data\n",
    "# Iterate over several given columns \n",
    "# only from the dataframe \n",
    "for column in df1[['ACEI_or_ARB', 'CAD', 'Concordance', 'DM', 'Gender', 'HTN', 'LBBB', 'MI', 'NYHA', 'Race','Smoking']]: \n",
    "     \n",
    "    # Select column contents by column    \n",
    "    # name using [] operator \n",
    "    columnSeriesObj = df1[column] \n",
    "    print('Column Name : ', column) \n",
    "    print('Column Count : ', columnSeriesObj.value_counts()) \n",
    "    print('Column Percentage : ', columnSeriesObj.value_counts(normalize = True)*100)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mean of all columns\n",
    "df1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation of all columns\n",
    "df1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert index type to list\n",
    "df1.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import normalize\n",
    "#df1_scaled = normalize(df1)\n",
    "#df1_scaled = pd.DataFrame(df1_scaled, columns=df1.columns)\n",
    "#df1_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance between each sample\n",
    "# linkage method defines how the distance between clusters is measured \n",
    "# In complete linkage, the distance between clusters is the distance between the furthest points of the clusters\n",
    "# In single linkage, the distance between clusters is the distance between the closest points of the clusters.\n",
    "\n",
    "# Perform the necessary imports\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the linkage: mergings\n",
    "mergings = linkage(df1, method='complete')\n",
    "\n",
    "# Plot the dendrogram, using varieties as labels\n",
    "plt.figure(figsize=(35,15))\n",
    "dendrogram(mergings,\n",
    "           labels=df1.index.tolist(),\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=8,color_threshold=240)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control number of clusters in the plot + add horizontal line.\n",
    "plt.figure(figsize=(35,15))\n",
    "dendrogram(mergings,\n",
    "           labels=df1.index.tolist(),\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=8,color_threshold=240)\n",
    "plt.axhline(y=400, c='black', lw=1, linestyle='dashed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshuffled the dataframe to confirm accuracy of HC\n",
    "df_shuf = df1.sample(frac=1)\n",
    "df_shuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part of the reshuffling process\n",
    "df_shuf1 = df1.sample(frac=1).reset_index(drop=True)\n",
    "df_shuf1 = df.set_index('New_ID', inplace=False)\n",
    "df_shuf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted the dataframe to list to be used as labels for the HC\n",
    "df_shuf.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion of dataframe column to list to be used as labels for the HC\n",
    "df_shuf1.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the linkage: mergings\n",
    "mergings1 = linkage(df_shuf, method='complete')\n",
    "\n",
    "# Plot the dendrogram, using varieties as labels\n",
    "plt.figure(figsize=(35,15))\n",
    "dendrogram(mergings1,\n",
    "           labels=df_shuf.index.tolist(),\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=8,color_threshold=240)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control number of clusters in the plot + add horizontal line.\n",
    "plt.figure(figsize=(35,15))\n",
    "dendrogram(mergings1,\n",
    "           labels=df_shuf.index.tolist(),\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=8,color_threshold=240)\n",
    "plt.axhline(y=400, c='black', lw=1, linestyle='dashed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the linkage: mergings\n",
    "mergings2 = linkage(df_shuf1, method='complete')\n",
    "\n",
    "# Plot the dendrogram, using varieties as labels\n",
    "plt.figure(figsize=(35,15))\n",
    "dendrogram(mergings2,\n",
    "           labels=df_shuf1.index.tolist(),\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=8,color_threshold=240)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control number of clusters in the plot + add horizontal line.\n",
    "plt.figure(figsize=(35,15))\n",
    "dendrogram(mergings2,\n",
    "           labels=df_shuf1.index.tolist(),\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=8,color_threshold=240)\n",
    "plt.axhline(y=400, c='black', lw=1, linestyle='dashed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since shuffling the dataset gives same dendrogram, we will go ahead and analyze the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "import pandas as pd\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "# Use fcluster to extract labels: labels\n",
    "labels = fcluster(mergings, 400, criterion='distance')\n",
    "print(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with labels and Response/No_response as columns: df2\n",
    "df2 = pd.DataFrame({'LABELS': labels, 'Res/No_Res': df1.index.tolist()})\n",
    "arranged_labels = df2.sort_values('LABELS')\n",
    "\n",
    "arranged_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create crosstab: ct\n",
    "ct = pd.crosstab(df2['LABELS'], df2['Res/No_Res'])\n",
    "# Display ct\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check cluster statistics\n",
    "arranged_labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the information in the arranged labels\n",
    "arranged_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To cull out cluster 1\n",
    "lab1 = arranged_labels[(arranged_labels['LABELS']==1)]\n",
    "print(lab1)\n",
    "print(lab1.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To filter patients with response in phenogroup 1\n",
    "# String to be searched in end of string  \n",
    "search1 =\"_NORES\"\n",
    "search2 =\"_RES\"\n",
    "  \n",
    "# boolean series returned with False at place of NaN \n",
    "NORES_df1 = lab1[\"Res/No_Res\"].str.endswith(search1, na = False) \n",
    "RES_df1 = lab1[\"Res/No_Res\"].str.endswith(search2, na = False)\n",
    "  \n",
    "# displaying filtered dataframe \n",
    "print(lab1[NORES_df1])\n",
    "print(lab1[NORES_df1].count())\n",
    "print('\\n')\n",
    "print(lab1[RES_df1])\n",
    "print(lab1[RES_df1].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index for cluster 1\n",
    "print(lab1.shape)\n",
    "lab1 = lab1.set_index('Res/No_Res', inplace=False)\n",
    "print(lab1.shape)\n",
    "clus1 = lab1.index.tolist()\n",
    "\n",
    "clus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select rows in cluster 1\n",
    "clus_1 = df1[df1.index.isin(clus1)]\n",
    "print(clus_1.shape)\n",
    "print(clus_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with its corresponding cluster number\n",
    "clus_1['New_group'] = 1\n",
    "print(clus_1.shape)\n",
    "print(clus_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To calculate the count and percentage of categorical variables in cluster 1\n",
    "# Iterate over many given columns \n",
    "# only from the dataframe \n",
    "for column in clus_1[['ACEI_or_ARB', 'CAD', 'Concordance', 'DM', 'Gender', 'HTN', 'LBBB', 'MI', 'NYHA', 'Race','Smoking']]: \n",
    "     \n",
    "    # Select column contents by column    \n",
    "    # name using [] operator \n",
    "    columnSeriesObj = clus_1[column] \n",
    "    print('Column Name : ', column) \n",
    "    print('Column Count : ', columnSeriesObj.value_counts()) \n",
    "    print('Column Percentage : ', columnSeriesObj.value_counts(normalize = True)*100)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To cull out cluster 2\n",
    "lab2 = arranged_labels[(arranged_labels['LABELS']==2)]\n",
    "print(lab2.count())\n",
    "print(lab2.shape)\n",
    "print(lab2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To filter patients with response in phenogroup 2\n",
    "# String to be searched in end of string  \n",
    "search1 =\"_NORES\"\n",
    "search2 =\"_RES\"\n",
    "  \n",
    "# boolean series returned with False at place of NaN \n",
    "NORES_df2 = lab2[\"Res/No_Res\"].str.endswith(search1, na = False) \n",
    "RES_df2 = lab2[\"Res/No_Res\"].str.endswith(search2, na = False)\n",
    "  \n",
    "# displaying filtered dataframe \n",
    "print(lab2[NORES_df2])\n",
    "print(lab2[NORES_df2].count())\n",
    "print('\\n')\n",
    "print(lab2[RES_df2])\n",
    "print(lab2[RES_df2].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index for cluster 2\n",
    "print(lab2.shape)\n",
    "lab2 = lab2.set_index(\"Res/No_Res\", inplace=False)\n",
    "print(lab2.shape)\n",
    "clus2 = lab2.index.tolist()\n",
    "\n",
    "clus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select rows in cluster 2\n",
    "clus_2 = df1[df1.index.isin(clus2)]\n",
    "print(clus_2.shape)\n",
    "print(clus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with its corresponding cluster number\n",
    "clus_2['New_group'] = 2\n",
    "print(clus_2.shape)\n",
    "print(clus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the count and percentage of categorical variables in cluster 2\n",
    "# Iterate over many given columns \n",
    "# only from the dataframe \n",
    "for column in clus_2[['ACEI_or_ARB', 'CAD', 'Concordance', 'DM', 'Gender', 'HTN', 'LBBB', 'MI', 'NYHA', 'Race','Smoking']]: \n",
    "     \n",
    "    # Select column contents by column    \n",
    "    # name using [] operator \n",
    "    columnSeriesObj = clus_2[column] \n",
    "    print('Column Name : ', column) \n",
    "    print('Column Count : ', columnSeriesObj.value_counts()) \n",
    "    print('Column Percentage : ', columnSeriesObj.value_counts(normalize = True)*100)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To cull out cluster 3\n",
    "lab3 = arranged_labels[(arranged_labels['LABELS']==3)]\n",
    "print(lab3)\n",
    "print(lab3.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To filter patients with response in phenogroup 3\n",
    "# String to be searched in end of string  \n",
    "search1 =\"_NORES\"\n",
    "search2 =\"_RES\"\n",
    "  \n",
    "# boolean series returned with False at place of NaN \n",
    "NORES_df3 = lab3[\"Res/No_Res\"].str.endswith(search1, na = False) \n",
    "RES_df3 = lab3[\"Res/No_Res\"].str.endswith(search2, na = False)\n",
    "  \n",
    "# displaying filtered dataframe \n",
    "print(lab3[NORES_df3])\n",
    "print(lab3[NORES_df3].count())\n",
    "print('\\n')\n",
    "print(lab3[RES_df3])\n",
    "print(lab3[RES_df3].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index for cluster 3\n",
    "print(lab3.shape)\n",
    "lab3 = lab3.set_index('Res/No_Res', inplace=False)\n",
    "print(lab3.shape)\n",
    "clus3 = lab3.index.tolist()\n",
    "\n",
    "clus3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select rows in cluster 3\n",
    "clus_3 = df1[df1.index.isin(clus3)]\n",
    "print(clus_3.shape)\n",
    "print(clus_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with its corresponding cluster number\n",
    "clus_3['New_group'] = 3\n",
    "print(clus_3.shape)\n",
    "print(clus_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the count and percentage of categorical variables in cluster 3\n",
    "# Iterate over many given columns \n",
    "# only from the dataframe \n",
    "for column in clus_3[['ACEI_or_ARB', 'CAD', 'Concordance', 'DM', 'Gender', 'HTN', 'LBBB', 'MI', 'NYHA', 'Race','Smoking']]: \n",
    "     \n",
    "    # Select column contents by column    \n",
    "    # name using [] operator \n",
    "    columnSeriesObj = clus_3[column] \n",
    "    print('Column Name : ', column) \n",
    "    print('Column Count : ', columnSeriesObj.value_counts()) \n",
    "    print('Column Percentage : ', columnSeriesObj.value_counts(normalize = True)*100)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To cull out cluster 4\n",
    "lab4 = arranged_labels[(arranged_labels['LABELS']==4)]\n",
    "print(lab4)\n",
    "print(lab4.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To filter patients with response in phenogroup 4\n",
    "# String to be searched in end of string  \n",
    "search1 =\"_NORES\"\n",
    "search2 =\"_RES\"\n",
    "  \n",
    "# boolean series returned with False at place of NaN \n",
    "NORES_df4 = lab4[\"Res/No_Res\"].str.endswith(search1, na = False) \n",
    "RES_df4 = lab4[\"Res/No_Res\"].str.endswith(search2, na = False)\n",
    "  \n",
    "# displaying filtered dataframe \n",
    "print(lab4[NORES_df4])\n",
    "print(lab4[NORES_df4].count())\n",
    "print('\\n')\n",
    "print(lab4[RES_df4])\n",
    "print(lab4[RES_df4].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index for cluster 4\n",
    "print(lab4.shape)\n",
    "lab4 = lab4.set_index(\"Res/No_Res\", inplace=False)\n",
    "print(lab4.shape)\n",
    "clus4 = lab4.index.tolist()\n",
    "\n",
    "clus4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select rows in cluster 4\n",
    "clus_4 = df1[df1.index.isin(clus4)]\n",
    "print(clus_4.shape)\n",
    "print(clus_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with its corresponding cluster number\n",
    "clus_4['New_group'] = 4\n",
    "print(clus_4.shape)\n",
    "print(clus_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the count and percentage of categorical variables in cluster 4\n",
    "# Iterate over many given columns \n",
    "# only from the dataframe \n",
    "for column in clus_4[['ACEI_or_ARB', 'CAD', 'Concordance', 'DM', 'Gender', 'HTN', 'LBBB', 'MI', 'NYHA', 'Race','Smoking']]: \n",
    "     \n",
    "    # Select column contents by column    \n",
    "    # name using [] operator \n",
    "    columnSeriesObj = clus_4[column] \n",
    "    print('Column Name : ', column) \n",
    "    print('Column Count : ', columnSeriesObj.value_counts()) \n",
    "    print('Column Percentage : ', columnSeriesObj.value_counts(normalize = True)*100)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of columns in phenogroup 1\n",
    "clus_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation of phenogroup 1\n",
    "clus_1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean of columns in phenogroup 2\n",
    "clus_2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation of columns in phenogroup 2\n",
    "clus_2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of columns in phenogroup 3\n",
    "clus_3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation of columns in phenogroup 3\n",
    "clus_3.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of columns in phenogroup 4\n",
    "clus_4.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# standard deviation of columns in phenogroup 4\n",
    "clus_4.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concatenating all phenogroups into a new dataframe\n",
    "new_df1 = pd.concat([clus_1, clus_2, clus_3, clus_4])\n",
    "print(new_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols  #ordinary squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of columns age and new_group\n",
    "new_df1.boxplot('Age', by='New_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding ANOVA of the above cell\n",
    "mod = ols('Age ~ New_group', data=new_df1).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of columns ECG_pre_QRSd and new_group\n",
    "new_df1.boxplot('ECG_pre_QRSd', by='New_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding ANOVA of the above cell\n",
    "mod = ols('ECG_pre_QRSd ~ New_group', data=new_df1).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of columns SPECT_pre_EDE and new_group\n",
    "new_df1.boxplot('SPECT_pre_EDE', by='New_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding ANOVA of the above cell\n",
    "mod = ols('SPECT_pre_EDE ~ New_group', data=new_df1).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of columns SPECT_pre_EDSI and new_group\n",
    "new_df1.boxplot(\"SPECT_pre_EDSI\", by=\"New_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding ANOVA of the above cell\n",
    "mod = ols('SPECT_pre_EDSI ~ New_group', data=new_df1).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of columns SPECT_pre_EDV and new_group\n",
    "new_df1.boxplot('SPECT_pre_EDV', by='New_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding ANOVA of the above cell\n",
    "mod = ols('SPECT_pre_EDV ~ New_group', data=new_df1).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of columns SPECT_pre_ESE and new_group\n",
    "new_df1.boxplot('SPECT_pre_ESE', by='New_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding ANOVA of the above cell\n",
    "mod = ols('SPECT_pre_ESE ~ New_group', data=new_df1).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of columns SPECT_pre_ESSI and new_group\n",
    "new_df1.boxplot('SPECT_pre_ESSI', by='New_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding ANOVA of the above cell\n",
    "mod = ols('SPECT_pre_ESSI ~ New_group', data=new_df1).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of columns SPECT_pre_ESV and new_group\n",
    "new_df1.boxplot('SPECT_pre_ESV', by='New_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding ANOVA of the above cell\n",
    "mod = ols('SPECT_pre_ESV ~ New_group', data=new_df1).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of columns SPECT_pre_LVEF and new_group\n",
    "new_df1.boxplot('SPECT_pre_LVEF', by='New_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding ANOVA of the above cell\n",
    "mod = ols('SPECT_pre_LVEF ~ New_group', data=new_df1).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of columns SPECT_pre_PBW and new_group\n",
    "new_df1.boxplot('SPECT_pre_PBW', by='New_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding ANOVA of the above cell\n",
    "mod = ols('SPECT_pre_PBW ~ New_group', data=new_df1).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of columns SPECT_pre_PSD and new_group\n",
    "new_df1.boxplot('SPECT_pre_PSD', by='New_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding ANOVA of the above cell\n",
    "mod = ols('SPECT_pre_PSD ~ New_group', data=new_df1).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of columns SPECT_pre_50scarand new_group\n",
    "new_df1.boxplot('SPECT_pre_50scar', by='New_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding ANOVA of the above cell\n",
    "mod = ols('SPECT_pre_50scar ~ New_group', data=new_df1).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of columns ECHO_pre_EDV and new_group\n",
    "new_df1.boxplot('Echo_pre_EDV', by='New_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding ANOVA of the above cell\n",
    "mod = ols('Echo_pre_EDV ~ New_group', data=new_df1).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of columns ECHO_pre_ESV and new_group\n",
    "new_df1.boxplot('Echo_pre_ESV', by='New_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding ANOVA of the above cell\n",
    "mod = ols('Echo_pre_ESV ~ New_group', data=new_df1).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of columns LVEF and new_group\n",
    "new_df1.boxplot('LVEF', by='New_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding ANOVA of the above cell\n",
    "mod = ols('LVEF ~ New_group', data=new_df1).fit()\n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab of the ACEI_ARB and new_group column \n",
    "ACEI_crosstab = pd.crosstab(new_df1['ACEI_or_ARB'], \n",
    "                            new_df1['New_group'],  \n",
    "                               margins = False) \n",
    "print(ACEI_crosstab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get chi-square value , p-value, degrees of freedom, expected frequencies using the function chi2_contingency\n",
    "stat, p, dof, expected = chi2_contingency(ACEI_crosstab)\n",
    "\n",
    "# select significance value\n",
    "alpha = 0.05\n",
    "# Determine whether to reject or keep your null hypothesis\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))\n",
    "if p <= alpha:\n",
    "    print('Phenogroups are associated (reject H0)')\n",
    "else:\n",
    "    print('Variables are not associated(fail to reject H0)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab of the CAD and new_group column\n",
    "CAD_crosstab = pd.crosstab(new_df1['CAD'], \n",
    "                            new_df1['New_group'],  \n",
    "                               margins = False) \n",
    "print(CAD_crosstab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get chi-square value , p-value, degrees of freedom, expected frequencies using the function chi2_contingency\n",
    "stat, p, dof, expected = chi2_contingency(CAD_crosstab)\n",
    "\n",
    "# select significance value\n",
    "alpha = 0.05\n",
    "# Determine whether to reject or keep your null hypothesis\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab of the Concordance and new_group column\n",
    "Con_crosstab = pd.crosstab(new_df1['Concordance'], \n",
    "                            new_df1['New_group'],  \n",
    "                               margins = False) \n",
    "print(Con_crosstab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get chi-square value , p-value, degrees of freedom, expected frequencies using the function chi2_contingency\n",
    "stat, p, dof, expected = chi2_contingency(Con_crosstab)\n",
    "\n",
    "# select significance value\n",
    "alpha = 0.05\n",
    "# Determine whether to reject or keep your null hypothesis\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))\n",
    "if p <= alpha:\n",
    "    print('Variables are associated (reject H0)')\n",
    "else:\n",
    "    print('Variables are not associated(fail to reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab of the DM and new_group column\n",
    "DM_crosstab = pd.crosstab(new_df1['DM'], \n",
    "                            new_df1['New_group'],  \n",
    "                               margins = False) \n",
    "print(DM_crosstab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi square test of the above cell\n",
    "stat, p, dof, expected = chi2_contingency(DM_crosstab)\n",
    "\n",
    "# select significance value\n",
    "alpha = 0.05\n",
    "# Determine whether to reject or keep your null hypothesis\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab of the Gender and new_group column\n",
    "Gender_crosstab = pd.crosstab(new_df1['Gender'], \n",
    "                            new_df1['New_group'],  \n",
    "                               margins = False) \n",
    "print(Gender_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi square test of the above cell\n",
    "stat, p, dof, expected = chi2_contingency(Gender_crosstab)\n",
    "\n",
    "# select significance value\n",
    "alpha = 0.05\n",
    "# Determine whether to reject or keep your null hypothesis\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab of the HTN and new_group column\n",
    "HTN_crosstab = pd.crosstab(new_df1['HTN'], \n",
    "                            new_df1['New_group'],  \n",
    "                               margins = False) \n",
    "print(HTN_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi square test of the above cell\n",
    "stat, p, dof, expected = chi2_contingency(HTN_crosstab)\n",
    "\n",
    "# select significance value\n",
    "alpha = 0.05\n",
    "# Determine whether to reject or keep your null hypothesis\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab of the LBBB and new_group column\n",
    "LBBB_crosstab = pd.crosstab(new_df1['LBBB'], \n",
    "                            new_df1['New_group'],  \n",
    "                               margins = False) \n",
    "print(LBBB_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi square test of the above cell\n",
    "stat, p, dof, expected = chi2_contingency(LBBB_crosstab)\n",
    "\n",
    "# select significance value\n",
    "alpha = 0.05\n",
    "# Determine whether to reject or keep your null hypothesis\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab of the MI and new_group column\n",
    "MI_crosstab = pd.crosstab(new_df1['MI'], \n",
    "                            new_df1['New_group'],  \n",
    "                               margins = False) \n",
    "print(MI_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi square test of the above cell\n",
    "stat, p, dof, expected = chi2_contingency(MI_crosstab)\n",
    "\n",
    "# select significance value\n",
    "alpha = 0.05\n",
    "# Determine whether to reject or keep your null hypothesis\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab of the NYHA and new_group column\n",
    "NYHA_crosstab = pd.crosstab(new_df1['NYHA'], \n",
    "                            new_df1['New_group'],  \n",
    "                               margins = False) \n",
    "print(NYHA_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi square test of the above cell\n",
    "stat, p, dof, expected = chi2_contingency(NYHA_crosstab)\n",
    "\n",
    "# select significance value\n",
    "alpha = 0.05\n",
    "# Determine whether to reject or keep your null hypothesis\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab of the Race and new_group column\n",
    "Race_crosstab = pd.crosstab(new_df1['Race'], \n",
    "                            new_df1['New_group'],  \n",
    "                               margins = False) \n",
    "print(Race_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi square test of the above cell\n",
    "stat, p, dof, expected = chi2_contingency(Race_crosstab)\n",
    "\n",
    "# select significance value\n",
    "alpha = 0.05\n",
    "# Determine whether to reject or keep your null hypothesis\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab of the Smoking and new_group column\n",
    "Smoking_crosstab = pd.crosstab(new_df1['Smoking'], \n",
    "                            new_df1['New_group'],  \n",
    "                               margins = False) \n",
    "print(Smoking_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi square test of the above cell\n",
    "stat, p, dof, expected = chi2_contingency(Smoking_crosstab)\n",
    "\n",
    "# select significance value\n",
    "alpha = 0.05\n",
    "# Determine whether to reject or keep your null hypothesis\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
