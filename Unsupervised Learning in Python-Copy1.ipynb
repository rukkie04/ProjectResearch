{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning\n",
    "* It finds pattern in Data\n",
    "* e.g clustering customers by their purchases\n",
    "* Compressing the data using purchase patterns (dimension reduction)\n",
    "### Supervised vs Unsupervised Learning\n",
    "* Supervised learning finds patterns for a prediction task\n",
    "* e.g classify tumors ads benign or cancerous (labels) \n",
    "* ...but without a specific prediction task in mind\n",
    "#### Iris Dataset\n",
    "* 2D Numpy Array\n",
    "* Columns are measurements(the features)\n",
    "* Rows represent iris plants (the samples)\n",
    "##### Iris data is 4-dimensional\n",
    "* Iris samples are points in 4-dimensional space\n",
    "* Dimension = number of features\n",
    "* Dimension too high to visualize\n",
    "* ...but unsupervised learning gives insight\n",
    "##### k-means clustering\n",
    "* Find clusters of samples\n",
    "* Number of clusters must be specified\n",
    "* Implemented in 'sklearn'(scikit-learn)\n",
    "\n",
    " from sklearn.cluster import KMeans\n",
    " model = KMeans(n_clusters=3)\n",
    " model.fit(samples)\n",
    " labels = model.predict(samples)\n",
    "##### Cluster labels for new samples\n",
    "* New samples can be assigned to existing clusters\n",
    "* k-means remember the means of each clusters (the centroids)\n",
    "* Finds the nearest centroid to each new sample\n",
    "new_label = model.predict(new_samples)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xs = [samples:,0]  Sepal length is in th 0th column\n",
    "\n",
    "ys = [samples:,2]   Petal length is in the 2nd column \n",
    "\n",
    "plt.scatter(xs,ys, c=labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### How many clusters?\n",
    "You are given an array points of size 300x2, where each row gives the (x, y) co-ordinates of a point on a map. Make a scatter plot of these points, and use the scatter plot to guess how many clusters there are.\n",
    "\n",
    "matplotlib.pyplot has already been imported as plt. In the IPython Shell:\n",
    "\n",
    "Create an array called xs that contains the values of points[:,0] - that is, column 0 of points.\n",
    "Create an array called ys that contains the values of points[:,1] - that is, column 1 of points.\n",
    "Make a scatter plot by passing xs and ys to the plt.scatter() function.\n",
    "Call the plt.show() function to show your plot.\n",
    "How many clusters do you see?\n",
    "\n",
    "#### Possible Answers\n",
    "2\n",
    "\n",
    "3   ### CORRECT answer\n",
    "\n",
    "300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Clustering 2D points\n",
    "From the scatter plot of the previous exercise, you saw that the points seem to separate into 3 clusters. You'll now create a KMeans model to find 3 clusters, and fit it to the data points from the previous exercise. After the model has been fit, you'll obtain the cluster labels for some new points using the .predict() method.\n",
    "\n",
    "You are given the array points from the previous exercise, and also an array new_points.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import KMeans from sklearn.cluster.\n",
    "Using KMeans(), create a KMeans instance called model to find 3 clusters. To specify the number of clusters, use the n_clusters keyword argument.\n",
    "Use the .fit() method of model to fit the model to the array of points points.\n",
    "Use the .predict() method of model to predict the cluster labels of new_points, assigning the result to labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'points' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a75db6ba84c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Fit model to points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Determine the cluster labels of new_points: labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'points' is not defined"
     ]
    }
   ],
   "source": [
    "# Import KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Create a KMeans instance with 3 clusters: model\n",
    "model = KMeans(n_clusters=3)\n",
    "\n",
    "# Fit model to points\n",
    "model.fit(points)\n",
    "\n",
    "# Determine the cluster labels of new_points: labels\n",
    "labels = model.predict(new_points)\n",
    "\n",
    "# Print cluster labels of new_points\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! You've successfully performed k-Means clustering and predicted the labels of new points. But it is not easy to inspect the clustering by just looking at the printed labels. A visualization would be far more useful. In the next exercise, you'll inspect your clustering with a scatter plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Inspect your clustering\n",
    "Let's now inspect the clustering you performed in the previous exercise!\n",
    "\n",
    "A solution to the previous exercise has already run, so new_points is an array of points and labels is the array of their cluster labels.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import matplotlib.pyplot as plt.\n",
    "Assign column 0 of new_points to xs, and column 1 of new_points to ys.\n",
    "Make a scatter plot of xs and ys, specifying the c=labels keyword arguments to color the points by their cluster label. Also specify alpha=0.5.\n",
    "Compute the coordinates of the centroids using the .cluster_centers_ attribute of model.\n",
    "Assign column 0 of centroids to centroids_x, and column 1 of centroids to centroids_y.\n",
    "Make a scatter plot of centroids_x and centroids_y, using 'D' (a diamond) as a marker by specifying the marker parameter. Set the size of the markers to be 50 using s=50.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KMeans' object has no attribute 'cluster_centers_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5e2da9b29f5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[1;31m# Assign the cluster centers: centroids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m \u001b[0mcentroids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;31m# Assign the columns of centroids: centroids_x, centroids_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KMeans' object has no attribute 'cluster_centers_'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "new_point = ([[ 4.00233332e-01, -1.26544471e+00],\n",
    "       [ 8.03230370e-01,  1.28260167e+00],\n",
    "       [-1.39507552e+00,  5.57292921e-02],\n",
    "       [-3.41192677e-01, -1.07661994e+00],\n",
    "       [ 1.54781747e+00,  1.40250049e+00],\n",
    "       [ 2.45032018e-01, -4.83442328e-01],\n",
    "       [ 1.20706886e+00,  8.88752605e-01],\n",
    "       [ 1.25132628e+00,  1.15555395e+00],\n",
    "       [ 1.81004415e+00,  9.65530731e-01],\n",
    "       [-1.66963401e+00, -3.08103509e-01],\n",
    "       [-7.17482105e-02, -9.37939700e-01],\n",
    "       [ 6.82631927e-01,  1.10258160e+00],\n",
    "       [ 1.09039598e+00,  1.43899529e+00],\n",
    "       [-1.67645414e+00, -5.04557049e-01],\n",
    "       [-1.84447804e+00,  4.52539544e-02],\n",
    "       [ 1.24234851e+00,  1.02088661e+00],\n",
    "       [-1.86147041e+00,  6.38645811e-03],\n",
    "       [-1.46044943e+00,  1.53252383e-01],\n",
    "       [ 4.98981817e-01,  8.98006058e-01],\n",
    "       [ 9.83962244e-01,  1.04369375e+00],\n",
    "       [-1.83136742e+00, -1.63632835e-01],\n",
    "       [ 1.30622617e+00,  1.07658717e+00],\n",
    "       [ 3.53420328e-01, -7.51320218e-01],\n",
    "       [ 1.13957970e+00,  1.54503860e+00],\n",
    "       [ 2.93995694e-01, -1.26135005e+00],\n",
    "       [-1.14558225e+00, -3.78709636e-02],\n",
    "       [ 1.18716105e+00,  6.00240663e-01],\n",
    "       [-2.23211946e+00,  2.30475094e-01],\n",
    "       [-1.28320430e+00, -3.93314568e-01],\n",
    "       [ 4.94296696e-01, -8.83972009e-01],\n",
    "       [ 6.31834930e-02, -9.11952228e-01],\n",
    "       [ 9.35759539e-01,  8.66820685e-01],\n",
    "       [ 1.58014721e+00,  1.03788392e+00],\n",
    "       [ 1.06304960e+00,  1.02706082e+00],\n",
    "       [-1.39732536e+00, -5.05162249e-01],\n",
    "       [-1.09935240e-01, -9.08113619e-01],\n",
    "       [ 1.17346758e+00,  9.47501092e-01],\n",
    "       [ 9.20084511e-01,  1.45767672e+00],\n",
    "       [ 5.82658956e-01, -9.00086832e-01],\n",
    "       [ 9.52772328e-01,  8.99042386e-01],\n",
    "       [-1.37266956e+00, -3.17878215e-02],\n",
    "       [ 2.12706760e-02, -7.07614194e-01],\n",
    "       [ 3.27049052e-01, -5.55998107e-01],\n",
    "       [-1.71590267e+00,  2.15222266e-01],\n",
    "       [ 5.12516209e-01, -7.60128245e-01],\n",
    "       [ 1.13023469e+00,  7.22451122e-01],\n",
    "       [-1.43074310e+00, -3.42787511e-01],\n",
    "       [-1.82724625e+00,  1.17657775e-01],\n",
    "       [ 1.41801350e+00,  1.11455080e+00],\n",
    "       [ 1.26897304e+00,  1.41925971e+00],\n",
    "       [ 8.04076494e-01,  1.63988557e+00],\n",
    "       [ 8.34567752e-01,  1.09956689e+00],\n",
    "       [-1.24714732e+00, -2.23522320e-01],\n",
    "       [-1.29422537e+00,  8.18770024e-02],\n",
    "       [-2.27378316e-01, -4.13331387e-01],\n",
    "       [ 2.18830387e-01, -4.68183120e-01],\n",
    "       [-1.22593414e+00,  2.55599147e-01],\n",
    "       [-1.31294033e+00, -4.28892070e-01],\n",
    "       [-1.33532382e+00,  6.52053776e-01],\n",
    "       [-3.01100233e-01, -1.25156451e+00],\n",
    "       [ 2.02778356e-01, -9.05277445e-01],\n",
    "       [ 1.01357784e+00,  1.12378981e+00],\n",
    "       [ 8.18324394e-01,  8.60841257e-01],\n",
    "       [ 1.26181556e+00,  1.46613744e+00],\n",
    "       [ 4.64867724e-01, -7.97212459e-01],\n",
    "       [ 3.60908898e-01,  8.44106720e-01],\n",
    "       [-2.15098310e+00, -3.69583937e-01],\n",
    "       [ 1.05005281e+00,  8.74181364e-01],\n",
    "       [ 1.06580074e-01, -7.49268153e-01],\n",
    "       [-1.73945723e+00,  2.52183577e-01],\n",
    "       [-1.12017687e-01, -6.52469788e-01],\n",
    "       [ 5.16618951e-01, -6.41267582e-01],\n",
    "       [ 3.26621787e-01, -8.80608015e-01],\n",
    "       [ 1.09017759e+00,  1.10952558e+00],\n",
    "       [ 3.64459576e-01, -6.94215622e-01],\n",
    "       [-1.90779318e+00,  1.87383674e-01],\n",
    "       [-1.95601829e+00,  1.39959126e-01],\n",
    "       [ 3.18541701e-01, -4.05271704e-01],\n",
    "       [ 7.36512699e-01,  1.76416255e+00],\n",
    "       [-1.44175162e+00, -5.72320429e-02],\n",
    "       [ 3.21757168e-01, -5.34283821e-01],\n",
    "       [-1.37317305e+00,  4.64484644e-02],\n",
    "       [ 6.87225910e-02, -1.10522944e+00],\n",
    "       [ 9.59314218e-01,  6.52316210e-01],\n",
    "       [-1.62641919e+00, -5.62423280e-01],\n",
    "       [ 1.06788305e+00,  7.29260482e-01],\n",
    "       [-1.79643547e+00, -9.88307418e-01],\n",
    "       [-9.88628377e-02, -6.81198092e-02],\n",
    "       [-1.05135700e-01,  1.17022143e+00],\n",
    "       [ 8.79964699e-01,  1.25340317e+00],\n",
    "       [ 9.80753407e-01,  1.15486539e+00],\n",
    "       [-8.33224966e-02, -9.24844368e-01],\n",
    "       [ 8.48759673e-01,  1.09397425e+00],\n",
    "       [ 1.32941649e+00,  1.13734563e+00],\n",
    "       [ 3.23788068e-01, -7.49732451e-01],\n",
    "       [-1.52610970e+00, -2.49016929e-01],\n",
    "       [-1.48598116e+00, -2.68828608e-01],\n",
    "       [-1.80479553e+00,  1.87052700e-01],\n",
    "       [-2.01907347e+00, -4.49511651e-01],\n",
    "       [ 2.87202402e-01, -6.55487415e-01],\n",
    "       [ 8.22295102e-01,  1.38443234e+00],\n",
    "       [-3.56997036e-02, -8.01825807e-01],\n",
    "       [-1.66955440e+00, -1.38258505e-01],\n",
    "       [-1.78226821e+00,  2.93353033e-01],\n",
    "       [ 7.25837138e-01, -6.23374024e-01],\n",
    "       [ 3.88432593e-01, -7.61283497e-01],\n",
    "       [ 1.49002783e+00,  7.95678671e-01],\n",
    "       [ 6.55423228e-04, -7.40580702e-01],\n",
    "       [-1.34533116e+00, -4.75629937e-01],\n",
    "       [-8.03845106e-01, -3.09943013e-01],\n",
    "       [-2.49041295e-01, -1.00662418e+00],\n",
    "       [-1.41095118e+00, -7.06744127e-02],\n",
    "       [-1.75119594e+00, -3.00491336e-01],\n",
    "       [-1.27942724e+00,  1.73774600e-01],\n",
    "       [ 3.35028183e-01,  6.24761151e-01],\n",
    "       [ 1.16819649e+00,  1.18902251e+00],\n",
    "       [ 7.15210457e-01,  9.26077419e-01],\n",
    "       [ 1.30057278e+00,  9.16349565e-01],\n",
    "       [-1.21697008e+00,  1.10039477e-01],\n",
    "       [-1.70707935e+00, -5.99659536e-02],\n",
    "       [ 1.20730655e+00,  1.05480463e+00],\n",
    "       [ 1.86896009e-01, -9.58047234e-01],\n",
    "       [ 8.03463471e-01,  3.86133140e-01],\n",
    "       [-1.73486790e+00, -1.49831913e-01],\n",
    "       [ 1.31261499e+00,  1.11802982e+00],\n",
    "       [ 4.04993148e-01, -5.10900347e-01],\n",
    "       [-1.93267968e+00,  2.20764694e-01],\n",
    "       [ 6.56004799e-01,  9.61887161e-01],\n",
    "       [-1.40588215e+00,  1.17134403e-01],\n",
    "       [-1.74306264e+00, -7.47473959e-02],\n",
    "       [ 5.43745412e-01,  1.47209224e+00],\n",
    "       [-1.97331669e+00, -2.27124493e-01],\n",
    "       [ 1.53901171e+00,  1.36049081e+00],\n",
    "       [-1.48323452e+00, -4.90302063e-01],\n",
    "       [ 3.86748484e-01, -1.26173400e+00],\n",
    "       [ 1.17015716e+00,  1.18549415e+00],\n",
    "       [-8.05381721e-02, -3.21923627e-01],\n",
    "       [-6.82273156e-02, -8.52825887e-01],\n",
    "       [ 7.13500028e-01,  1.27868520e+00],\n",
    "       [-1.85014378e+00, -5.03490558e-01],\n",
    "       [ 6.36085266e-02, -1.41257040e+00],\n",
    "       [ 1.52966062e+00,  9.66056572e-01],\n",
    "       [ 1.62165714e-01, -1.37374843e+00],\n",
    "       [-3.23474497e-01, -7.06620269e-01],\n",
    "       [-1.51768993e+00,  1.87658302e-01],\n",
    "       [ 8.88895911e-01,  7.62237161e-01],\n",
    "       [ 4.83164032e-01,  8.81931869e-01],\n",
    "       [-5.52997766e-02, -7.11305016e-01],\n",
    "       [-1.57966441e+00, -6.29220313e-01],\n",
    "       [ 5.51308645e-02, -8.47206763e-01],\n",
    "       [-2.06001582e+00,  5.87697787e-02],\n",
    "       [ 1.11810855e+00,  1.30254175e+00],\n",
    "       [ 4.87016164e-01, -9.90143937e-01],\n",
    "       [-1.65518042e+00, -1.69386383e-01],\n",
    "       [-1.44349738e+00,  1.90299243e-01],\n",
    "       [-1.70074547e-01, -8.26736022e-01],\n",
    "       [-1.82433979e+00, -3.07814626e-01],\n",
    "       [ 1.03093485e+00,  1.26457691e+00],\n",
    "       [ 1.64431169e+00,  1.27773115e+00],\n",
    "       [-1.47617693e+00,  2.60783872e-02],\n",
    "       [ 1.00953067e+00,  1.14270181e+00],\n",
    "       [-1.45285636e+00, -2.55216207e-01],\n",
    "       [-1.74092917e+00, -8.34443177e-02],\n",
    "       [ 1.22038299e+00,  1.28699961e+00],\n",
    "       [ 9.16925397e-01,  7.32070275e-01],\n",
    "       [-1.60754185e-03, -7.26375571e-01],\n",
    "       [ 8.93841238e-01,  8.41146643e-01],\n",
    "       [ 6.33791961e-01,  1.00915134e+00],\n",
    "       [-1.47927075e+00, -6.99781936e-01],\n",
    "       [ 5.44799374e-02, -1.06441970e+00],\n",
    "       [-1.51935568e+00, -4.89276929e-01],\n",
    "       [ 2.89939026e-01, -7.73145523e-01],\n",
    "       [-9.68154061e-03, -1.13302207e+00],\n",
    "       [ 1.13474639e+00,  9.71541744e-01],\n",
    "       [ 5.36421406e-01, -8.47906388e-01],\n",
    "       [ 1.14759864e+00,  6.89915205e-01],\n",
    "       [ 5.73291902e-01,  7.90802710e-01],\n",
    "       [ 2.12377397e-01, -6.07569808e-01],\n",
    "       [ 5.26579548e-01, -8.15930264e-01],\n",
    "       [-2.01831641e+00,  6.78650740e-02],\n",
    "       [-2.35512624e-01, -1.08205132e+00],\n",
    "       [ 1.59274780e-01, -6.00717261e-01],\n",
    "       [ 2.28120356e-01, -1.16003549e+00],\n",
    "       [-1.53658378e+00,  8.40798808e-02],\n",
    "       [ 1.13954609e+00,  6.31782001e-01],\n",
    "       [ 1.01119255e+00,  1.04360805e+00],\n",
    "       [-1.42039867e-01, -4.81230337e-01],\n",
    "       [-2.23120182e+00,  8.49162905e-02],\n",
    "       [ 1.25554811e-01, -1.01794793e+00],\n",
    "       [-1.72493509e+00, -6.94426177e-01],\n",
    "       [-1.60434630e+00,  4.45550868e-01],\n",
    "       [ 7.37153979e-01,  9.26560744e-01],\n",
    "       [ 6.72905271e-01,  1.13366030e+00],\n",
    "       [ 1.20066456e+00,  7.26273093e-01],\n",
    "       [ 7.58747209e-02, -9.83378326e-01],\n",
    "       [ 1.28783262e+00,  1.18088601e+00],\n",
    "       [ 1.06521930e+00,  1.00714746e+00],\n",
    "       [ 1.05871698e+00,  1.12956519e+00],\n",
    "       [-1.12643410e+00,  1.66787744e-01],\n",
    "       [-1.10157218e+00, -3.64137806e-01],\n",
    "       [ 2.35118217e-01, -1.39769949e-01],\n",
    "       [ 1.13853795e+00,  1.01018519e+00],\n",
    "       [ 5.31205654e-01, -8.81990792e-01],\n",
    "       [ 4.33085936e-01, -7.64059042e-01],\n",
    "       [-4.48926156e-03, -1.30548411e+00],\n",
    "       [-1.76348589e+00, -4.97430739e-01],\n",
    "       [ 1.36485681e+00,  5.83404699e-01],\n",
    "       [ 5.66923900e-01,  1.51391963e+00],\n",
    "       [ 1.35736826e+00,  6.70915318e-01],\n",
    "       [ 1.07173397e+00,  6.11990884e-01],\n",
    "       [ 1.00106915e+00,  8.93815326e-01],\n",
    "       [ 1.33091007e+00,  8.79773879e-01],\n",
    "       [-1.79603740e+00, -3.53883973e-02],\n",
    "       [-1.27222979e+00,  4.00156642e-01],\n",
    "       [ 8.47480603e-01,  1.17032364e+00],\n",
    "       [-1.50989129e+00, -7.12318330e-01],\n",
    "       [-1.24953576e+00, -5.57859730e-01],\n",
    "       [-1.27717973e+00, -5.99350550e-01],\n",
    "       [-1.81946743e+00,  7.37057673e-01],\n",
    "       [ 1.19949867e+00,  1.56969386e+00],\n",
    "       [-1.25543847e+00, -2.33892826e-01],\n",
    "       [-1.63052058e+00,  1.61455865e-01],\n",
    "       [ 1.10611305e+00,  7.39698224e-01],\n",
    "       [ 6.70193192e-01,  8.70567001e-01],\n",
    "       [ 3.69670156e-01, -6.94645306e-01],\n",
    "       [-1.26362293e+00, -6.99249285e-01],\n",
    "       [-3.66687507e-01, -1.35310260e+00],\n",
    "       [ 2.44032147e-01, -6.59470793e-01],\n",
    "       [-1.27679142e+00, -4.85453412e-01],\n",
    "       [ 3.77473612e-02, -6.99251605e-01],\n",
    "       [-2.19148539e+00, -4.91199500e-01],\n",
    "       [-2.93277777e-01, -5.89488212e-01],\n",
    "       [-1.65737397e+00, -2.98337786e-01],\n",
    "       [ 7.36638861e-01,  5.78037057e-01],\n",
    "       [ 1.13709081e+00,  1.30119754e+00],\n",
    "       [-1.44146601e+00,  3.13934680e-02],\n",
    "       [ 5.92360708e-01,  1.22545114e+00],\n",
    "       [ 6.51719414e-01,  4.92674894e-01],\n",
    "       [ 5.94559139e-01,  8.25637315e-01],\n",
    "       [-1.87900722e+00, -5.21899626e-01],\n",
    "       [ 2.15225041e-01, -1.28269851e+00],\n",
    "       [ 4.99145965e-01, -6.70268634e-01],\n",
    "       [-1.82954176e+00, -3.39269731e-01],\n",
    "       [ 7.92721403e-01,  1.33785606e+00],\n",
    "       [ 9.54363372e-01,  9.80396626e-01],\n",
    "       [-1.35359846e+00,  1.03976340e-01],\n",
    "       [ 1.05595062e+00,  8.07031927e-01],\n",
    "       [-1.94311010e+00, -1.18976964e-01],\n",
    "       [-1.39604137e+00, -3.10095976e-01],\n",
    "       [ 1.28977624e+00,  1.01753365e+00],\n",
    "       [-1.59503139e+00, -5.40574609e-01],\n",
    "       [-1.41994046e+00, -3.81032569e-01],\n",
    "       [-2.35569801e-02, -1.10133702e+00],\n",
    "       [-1.26038568e+00, -6.93273886e-01],\n",
    "       [ 9.60215981e-01, -8.11553694e-01],\n",
    "       [ 5.51803308e-01, -1.01793176e+00],\n",
    "       [ 3.70185085e-01, -1.06885468e+00],\n",
    "       [ 8.25529207e-01,  8.77007060e-01],\n",
    "       [-1.87032595e+00,  2.87507199e-01],\n",
    "       [-1.56260769e+00, -1.89196712e-01],\n",
    "       [-1.26346548e+00, -7.74725237e-01],\n",
    "       [-6.33800421e-02, -7.59400611e-01],\n",
    "       [ 8.85298280e-01,  8.85620519e-01],\n",
    "       [-1.43324686e-01, -1.16083678e+00],\n",
    "       [-1.83908725e+00, -3.26655515e-01],\n",
    "       [ 2.74709229e-01, -1.04546829e+00],\n",
    "       [-1.45703573e+00, -2.91842036e-01],\n",
    "       [-1.59048842e+00,  1.66063031e-01],\n",
    "       [ 9.25549284e-01,  7.41406406e-01],\n",
    "       [ 1.97245469e-01, -7.80703225e-01],\n",
    "       [ 2.88401697e-01, -8.32425551e-01],\n",
    "       [ 7.24141618e-01, -7.99149200e-01],\n",
    "       [-1.62658639e+00, -1.80005543e-01],\n",
    "       [ 5.84481588e-01,  1.13195640e+00],\n",
    "       [ 1.02146732e+00,  4.59657799e-01],\n",
    "       [ 8.65050554e-01,  9.57714887e-01],\n",
    "       [ 3.98717766e-01, -1.24273147e+00],\n",
    "       [ 8.62234892e-01,  1.10955561e+00],\n",
    "       [-1.35999430e+00,  2.49942654e-02],\n",
    "       [-1.19178505e+00, -3.82946323e-02],\n",
    "       [ 1.29392424e+00,  1.10320509e+00],\n",
    "       [ 1.25679630e+00, -7.79857582e-01],\n",
    "       [ 9.38040302e-02, -5.53247258e-01],\n",
    "       [-1.73512175e+00, -9.76271667e-02],\n",
    "       [ 2.23153587e-01, -9.43474351e-01],\n",
    "       [ 4.01989100e-01, -1.10963051e+00],\n",
    "       [-1.42244158e+00,  1.81914703e-01],\n",
    "       [ 3.92476267e-01, -8.78426277e-01],\n",
    "       [ 1.25181875e+00,  6.93614996e-01],\n",
    "       [ 1.77481317e-02, -7.20304235e-01],\n",
    "       [-1.87752521e+00, -2.63870424e-01],\n",
    "       [-1.58063602e+00, -5.50456344e-01],\n",
    "       [-1.59589493e+00, -1.53932892e-01],\n",
    "       [-1.01829770e+00,  3.88542370e-02],\n",
    "       [ 1.24819659e+00,  6.60041803e-01],\n",
    "       [-1.25551377e+00, -2.96172009e-02],\n",
    "       [-1.41864559e+00, -3.58230179e-01],\n",
    "       [ 5.25758326e-01,  8.70500543e-01],\n",
    "       [ 5.55599988e-01,  1.18765072e+00],\n",
    "       [ 2.81344439e-02, -6.99111314e-01]])\n",
    "new_points = np.array(new_point)\n",
    "\n",
    "labels = np.array([1, 2, 0, 1, 2, 1, 2, 2, 2, 0, 1, 2, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2,\n",
    "       1, 2, 1, 0, 2, 0, 0, 1, 1, 2, 2, 2, 0, 1, 2, 2, 1, 2, 0, 1, 1, 0,\n",
    "       1, 2, 0, 0, 2, 2, 2, 2, 0, 0, 1, 1, 0, 0, 0, 1, 1, 2, 2, 2, 1, 2,\n",
    "       0, 2, 1, 0, 1, 1, 1, 2, 1, 0, 0, 1, 2, 0, 1, 0, 1, 2, 0, 2, 0, 1,\n",
    "       2, 2, 2, 1, 2, 2, 1, 0, 0, 0, 0, 1, 2, 1, 0, 0, 1, 1, 2, 1, 0, 0,\n",
    "       1, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 1, 2, 0, 2, 1, 0, 2, 0, 0, 2, 0,\n",
    "       2, 0, 1, 2, 1, 1, 2, 0, 1, 2, 1, 1, 0, 2, 2, 1, 0, 1, 0, 2, 1, 0,\n",
    "       0, 1, 0, 2, 2, 0, 2, 0, 0, 2, 2, 1, 2, 2, 0, 1, 0, 1, 1, 2, 1, 2,\n",
    "       2, 1, 1, 0, 1, 1, 1, 0, 2, 2, 1, 0, 1, 0, 0, 2, 2, 2, 1, 2, 2, 2,\n",
    "       0, 0, 1, 2, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2,\n",
    "       0, 0, 2, 2, 1, 0, 1, 1, 0, 1, 0, 1, 0, 2, 2, 0, 2, 2, 2, 0, 1, 1,\n",
    "       0, 2, 2, 0, 2, 0, 0, 2, 0, 0, 1, 0, 1, 1, 1, 2, 0, 0, 0, 1, 2, 1,\n",
    "       0, 1, 0, 0, 2, 1, 1, 1, 0, 2, 2, 2, 1, 2, 0, 0, 2, 1, 1, 0, 1, 1,\n",
    "       0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1])\n",
    "\n",
    "\n",
    "# Assign the columns of new_points: xs and ys\n",
    "xs = new_points[:, 0]\n",
    "ys = new_points[:, 1]\n",
    "\n",
    "# Make a scatter plot of xs and ys, using labels to define the colors\n",
    "plt.scatter(xs, ys, c=labels, alpha=0.5)\n",
    "\n",
    "# Assign the cluster centers: centroids\n",
    "centroids = model.cluster_centers_\n",
    "\n",
    "# Assign the columns of centroids: centroids_x, centroids_y\n",
    "centroids_x = centroids[:,0]\n",
    "centroids_y = centroids[:,1]\n",
    "\n",
    "# Make a scatter plot of centroids_x and centroids_y\n",
    "plt.scatter(centroids_x, centroids_y, marker='D', s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! The clustering looks great! But how can you be sure that 3 clusters is the correct choice? In other words, how can you evaluate the quality of a clustering? Tune into the next video in which Ben will explain how to evaluate a clustering!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating a clustering\n",
    "* can check correspondings with eg. iris species\n",
    "* ...but what if there are no species to check against?\n",
    "* Measure quality of clustering\n",
    "* Informs choice of how many clusters to look for \n",
    "#### Iris: clusters vs species\n",
    "* KMeans found three clusters amongs the iris sample\n",
    "* Do the clusters correspond to the species\n",
    "#### Cross tabulation with pandas\n",
    "* Clusters vs species is a 'cross tabulation'\n",
    "* Use the pandas library\n",
    "* Given the species of each sample as a list species\n",
    "species = ['setosa','setosa','vesicolor','virginica',...]\n",
    "#### Aligning labels and species\n",
    "import pandas as pd\n",
    "pd.DataFrame({'labels':labels 'species':species})\n",
    "print(df)\n",
    "#### Crosstab of labels and species\n",
    "ct= pd.crosstab(df['labels'], df['species'])\n",
    "print(ct)\n",
    "##### How to evaluate a clustering if there were no species information?\n",
    "##### Measuring cluster quality\n",
    "* using only samples and their cluster labels\n",
    "* A good clustering has tight clusters\n",
    "* Samples in each cluster bunched together\n",
    "##### Inertia measures the quality of clustering\n",
    "* Measures how spread out the clusters are (lower is better)\n",
    "* Distance from each sample to centroid of its cluster \n",
    "* After fit(), available as attribute inertia_\n",
    "* KMeans attempts to minimize the inertia when choosing clusters\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(samples)\n",
    "print(model.inertia_)\n",
    "##### The number of clusters\n",
    "* Clusterings of the iris dataset with different numbers of clusters\n",
    "* More clusters mean lower inertia\n",
    "* What is the best number of clusters?\n",
    "* A good clustering has tight clusters (so low inertia) BUT NOT TOO MANY CLUSTERS\n",
    "* Choose an 'elbow' in the inertia plot where inertia begins to decrease more slowly\n",
    "* eg for iris dataset, 3 is a good choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### How many clusters of grain?\n",
    "In the video, you learned how to choose a good number of clusters for a dataset using the k-means inertia graph. You are given an array samples containing the measurements (such as area, perimeter, length, and several others) of samples of grain. What's a good number of clusters in this case?\n",
    "\n",
    "KMeans and PyPlot (plt) have already been imported for you.\n",
    "\n",
    "This dataset was sourced from the UCI Machine Learning Repository.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "For each of the given values of k, perform the following steps:\n",
    "Create a KMeans instance called model with k clusters.\n",
    "Fit the model to the grain data samples.\n",
    "Append the value of the inertia_ attribute of model to the list inertias.\n",
    "The code to plot ks vs inertias has been written for you, so hit 'Submit Answer' to see the plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1, 6)\n",
    "inertias = []\n",
    "\n",
    "for k in ks:\n",
    "    # Create a KMeans instance with k clusters: model\n",
    "    model = KMeans(n_clusters=k)\n",
    "    \n",
    "    # Fit model to samples\n",
    "    model.fit(samples)\n",
    "    \n",
    "    # Append the inertia to the list of inertias\n",
    "    inertias.append(model.inertia_)\n",
    "    \n",
    "# Plot ks vs inertias\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent job! The inertia decreases very slowly from 3 clusters to 4, so it looks like 3 clusters would be a good choice for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Evaluating the grain clustering\n",
    "In the previous exercise, you observed from the inertia plot that 3 is a good number of clusters for the grain data. In fact, the grain samples come from a mix of 3 different grain varieties: \"Kama\", \"Rosa\" and \"Canadian\". In this exercise, cluster the grain samples into three clusters, and compare the clusters to the grain varieties using a cross-tabulation.\n",
    "\n",
    "You have the array samples of grain samples, and a list varieties giving the grain variety for each sample. Pandas (pd) and KMeans have already been imported for you.\n",
    "\n",
    "### Instructions\n",
    "Create a KMeans model called model with 3 clusters.\n",
    "Use the .fit_predict() method of model to fit it to samples and derive the cluster labels. Using .fit_predict() is the same as using .fit() followed by .predict().\n",
    "Create a DataFrame df with two columns named 'labels' and 'varieties', using labels and varieties, respectively, for the column values. This has been done for you.\n",
    "Use the pd.crosstab() function on df['labels'] and df['varieties'] to count the number of times each grain variety coincides with each cluster label. Assign the result to ct.\n",
    "Hit 'Submit Answer' to see the cross-tabulation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KMeans model with 3 clusters: model\n",
    "model = KMeans(n_clusters=3)\n",
    "\n",
    "# Use fit_predict to fit model and obtain cluster labels: labels\n",
    "labels = model.fit_predict(samples)\n",
    "\n",
    "# Create a DataFrame with labels and varieties as columns: df\n",
    "df = pd.DataFrame({'labels': labels, 'varieties': varieties})\n",
    "\n",
    "# Create crosstab: ct\n",
    "ct = pd.crosstab(df['labels'], df['varieties'])\n",
    "\n",
    "# Display ct\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! The cross-tabulation shows that the 3 varieties of grain separate really well into 3 clusters. But depending on the type of data you are working with, the clustering may not always be this good. Is there anything you can do in such situations to improve your clustering? You'll find out in the next video!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming features for better clustering\n",
    "##### Piedmont wine dataset\n",
    "* 178 samples from 3 distinct varieties of red wine: Barolo, Grignogrilo, Barela\n",
    "* Features measure chemical composition eg alcohol content\n",
    "* Visual properties like \"color intensity\"\n",
    "* To check cluster label vs wine varieties correspondence, you use the dataframe and crosstab code\n",
    "* Here the KMeans clusters dont correspond well with the wine varieties\n",
    "##### Feature variances\n",
    "* The wine features have very different variances\n",
    "* Variance of a feature measures spread of its values \n",
    "##### StandardScaler\n",
    "* In KMeans: feature variance = feature influence\n",
    "* To give every feature a chance, they have to be transformed \n",
    "* StandardScaler transforms each feature to have a mean of 0 and variance of 1\n",
    "* Features are said to be \"Standardized\"\n",
    "sklearn Standardscaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(samples)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "samples_scaled= scaler.transform(samples)\n",
    "##### Similar Methods\n",
    "* The API of Standardscaler and KMeans are similar\n",
    "* Important difference is StandardScaler transforms the data (as a transformer)\n",
    "* ..and KMeans in contrast assigns cluster labels to samples and this is done with the predict method\n",
    "##### To do clustering: StandardScaler, then KMeans\n",
    "* Use sklearn pipeline to combine multiple steps\n",
    "* Data flows from one step into the next\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "scaler= StandardScaler()\n",
    "Kmeans = KMeans(n_clusters=3)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipeline= make_pipeline(scaler,KMeans)\n",
    "pipeline.fit(samples)\n",
    "labels = pipeline.predict(samples)\n",
    "###### Feature standardization improves clustering\n",
    "* StandardScaler is a preprocessing step\n",
    "* MaxAbsScaler and Normalizer are other examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Scaling fish data for clustering\n",
    "You are given an array samples giving measurements of fish. Each row represents an individual fish. The measurements, such as weight in grams, length in centimeters, and the percentage ratio of height to length, have very different scales. In order to cluster this data effectively, you'll need to standardize these features first. In this exercise, you'll build a pipeline to standardize and cluster the data.\n",
    "\n",
    "These fish measurement data were sourced from the Journal of Statistics Education.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import:\n",
    "make_pipeline from sklearn.pipeline.\n",
    "StandardScaler from sklearn.preprocessing.\n",
    "KMeans from sklearn.cluster.\n",
    "Create an instance of StandardScaler called scaler.\n",
    "Create an instance of KMeans with 4 clusters called kmeans.\n",
    "Create a pipeline called pipeline that chains scaler and kmeans. To do this, you just need to pass them in as arguments to make_pipeline().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create scaler: scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create KMeans instance: kmeans\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "\n",
    "# Create pipeline: pipeline\n",
    "pipeline = make_pipeline(scaler, kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! Now that you've built the pipeline, you'll use it in the next exercise to cluster the fish by their measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Clustering the fish data\n",
    "You'll now use your standardization and clustering pipeline from the previous exercise to cluster the fish by their measurements, and then create a cross-tabulation to compare the cluster labels with the fish species.\n",
    "\n",
    "As before, samples is the 2D array of fish measurements. Your pipeline is available as pipeline, and the species of every fish sample is given by the list species.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import pandas as pd.\n",
    "Fit the pipeline to the fish measurements samples.\n",
    "Obtain the cluster labels for samples by using the .predict() method of pipeline.\n",
    "Using pd.DataFrame(), create a DataFrame df with two columns named 'labels' and 'species', using labels and species, respectively, for the column values.\n",
    "Using pd.crosstab(), create a cross-tabulation ct of df['labels'] and df['species'].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Fit the pipeline to samples\n",
    "pipeline.fit(samples)\n",
    "\n",
    "# Calculate the cluster labels: labels\n",
    "labels = pipeline.predict(samples)\n",
    "\n",
    "# Create a DataFrame with labels and species as columns: df\n",
    "df = pd.DataFrame({'labels': labels, 'species': species})\n",
    "\n",
    "# Create crosstab: ct\n",
    "ct = pd.crosstab(df['labels'], df['species'])\n",
    "\n",
    "# Display ct\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! It looks like the fish data separates really well into 4 clusters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Clustering stocks using KMeans\n",
    "In this exercise, you'll cluster companies using their daily stock price movements (i.e. the dollar difference between the closing and opening prices for each trading day). You are given a NumPy array movements of daily price movements from 2010 to 2015 (obtained from Yahoo! Finance), where each row corresponds to a company, and each column corresponds to a trading day.\n",
    "\n",
    "Some stocks are more expensive than others. To account for this, include a Normalizer at the beginning of your pipeline. The Normalizer will separately transform each company's stock price to a relative scale before the clustering begins.\n",
    "\n",
    "Note that Normalizer() is different to StandardScaler(), which you used in the previous exercise. While StandardScaler() standardizes features (such as the features of the fish data from the previous exercise) by removing the mean and scaling to unit variance, Normalizer() rescales each sample - here, each company's stock price - independently of the other.\n",
    "\n",
    "KMeans and make_pipeline have already been imported for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import Normalizer from sklearn.preprocessing.\n",
    "Create an instance of Normalizer called normalizer.\n",
    "Create an instance of KMeans called kmeans with 10 clusters.\n",
    "Using make_pipeline(), create a pipeline called pipeline that chains normalizer and kmeans.\n",
    "Fit the pipeline to the movements array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Normalizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# Create a normalizer: normalizer\n",
    "normalizer = Normalizer()\n",
    "\n",
    "# Create a KMeans model with 10 clusters: kmeans\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "\n",
    "# Make a pipeline chaining normalizer and kmeans: pipeline\n",
    "pipeline = make_pipeline(normalizer, kmeans)\n",
    "\n",
    "# Fit pipeline to the daily price movements\n",
    "pipeline.fit(movements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work - you're really getting the hang of this. Now that your pipeline has been set up, you can find out which stocks move together in the next exercise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Which stocks move together?\n",
    "In the previous exercise, you clustered companies by their daily stock price movements. So which company have stock prices that tend to change in the same way? You'll now inspect the cluster labels from your clustering to find out.\n",
    "\n",
    "Your solution to the previous exercise has already been run. Recall that you constructed a Pipeline pipeline containing a KMeans model and fit it to the NumPy array movements of daily stock movements. In addition, a list companies of the company names is available.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import pandas as pd.\n",
    "Use the .predict() method of the pipeline to predict the labels for movements.\n",
    "Align the cluster labels with the list of company names companies by creating a DataFrame df with labels and companies as columns. This has been done for you.\n",
    "Use the .sort_values() method of df to sort the DataFrame by the 'labels' column, and print the result.\n",
    "Hit 'Submit Answer' and take a moment to see which companies are together in each cluster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Predict the cluster labels: labels\n",
    "labels = pipeline.predict(movements)\n",
    "\n",
    "# Create a DataFrame aligning labels and companies: df\n",
    "df = pd.DataFrame({'labels': labels, 'companies': companies})\n",
    "sort_values = df.sort_values('labels')\n",
    "# Display df sorted by cluster label\n",
    "print(sort_values)\n",
    "\n",
    "script.py> output:\n",
    "        labels                           companies\n",
    "    59       0                               Yahoo\n",
    "    15       0                                Ford\n",
    "    35       0                            Navistar\n",
    "    26       1                      JPMorgan Chase\n",
    "    16       1                   General Electrics\n",
    "    58       1                               Xerox\n",
    "    11       1                               Cisco\n",
    "    18       1                       Goldman Sachs\n",
    "    20       1                          Home Depot\n",
    "    5        1                     Bank of America\n",
    "    3        1                    American express\n",
    "    55       1                         Wells Fargo\n",
    "    1        1                                 AIG\n",
    "    38       2                               Pepsi\n",
    "    40       2                      Procter Gamble\n",
    "    28       2                           Coca Cola\n",
    "    27       2                      Kimberly-Clark\n",
    "    9        2                   Colgate-Palmolive\n",
    "    54       3                            Walgreen\n",
    "    36       3                    Northrop Grumman\n",
    "    29       3                     Lookheed Martin\n",
    "    4        3                              Boeing\n",
    "    0        4                               Apple\n",
    "    47       4                            Symantec\n",
    "    33       4                           Microsoft\n",
    "    32       4                                  3M\n",
    "    31       4                           McDonalds\n",
    "    30       4                          MasterCard\n",
    "    50       4  Taiwan Semiconductor Manufacturing\n",
    "    14       4                                Dell\n",
    "    17       4                     Google/Alphabet\n",
    "    24       4                               Intel\n",
    "    23       4                                 IBM\n",
    "    2        4                              Amazon\n",
    "    51       4                   Texas instruments\n",
    "    43       4                                 SAP\n",
    "    45       5                                Sony\n",
    "    48       5                              Toyota\n",
    "    21       5                               Honda\n",
    "    22       5                                  HP\n",
    "    34       5                          Mitsubishi\n",
    "    7        5                               Canon\n",
    "    56       6                            Wal-Mart\n",
    "    57       7                               Exxon\n",
    "    44       7                        Schlumberger\n",
    "    8        7                         Caterpillar\n",
    "    10       7                      ConocoPhillips\n",
    "    12       7                             Chevron\n",
    "    13       7                   DuPont de Nemours\n",
    "    53       7                       Valero Energy\n",
    "    39       8                              Pfizer\n",
    "    41       8                       Philip Morris\n",
    "    25       8                   Johnson & Johnson\n",
    "    49       9                               Total\n",
    "    46       9                      Sanofi-Aventis\n",
    "    37       9                            Novartis\n",
    "    42       9                   Royal Dutch Shell\n",
    "    19       9                     GlaxoSmithKline\n",
    "    52       9                            Unilever\n",
    "    6        9            British American Tobacco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic job - you have completed Chapter 1! Take a look at the clusters. Are you surprised by any of the results? In the next chapter, you'll learn about how to communicate results such as this through visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 unsupervised visual learning techniques for visualization\n",
    "* tSNE and hierarchical clustering\n",
    "* t-SNE creates a 2D map of a dataset and contains useful information about the proximity of samples to one another\n",
    "* Heirarchical clustering (HC) arranges samples into a hierarchy of clusters\n",
    "* HC can organize any sort of data into a heirarchy\n",
    "##### Using the Eurovision scoring dataset\n",
    "* Describes how countries gave scores to the Eurovision 2016 contest\n",
    "* 2D array of scores\n",
    "* Rows are countries, columns are scores\n",
    "* The result of the HC of the countries can be visualized in a tree-like diagram called a DENDROGRAM\n",
    "* The Dendrogram groups the countries together into larger and larger clusters\n",
    "* ..and many of these countries are recognized as countries that are related geographically\n",
    "* ..or close cultural or political ties or they belong to a single language group\n",
    "##### How HC is done\n",
    "* Every country begins in a seperate cluster\n",
    "* At each step, the 2 closest clusters are merged\n",
    "* This continues until all countries are in a single cluster\n",
    "* This type of HC is called AGGLOMERATIVE HC\n",
    "* There is also DIVISIVE HC which works the other way\n",
    "##### The Dendrogram of a HC\n",
    "* Read from bottom up\n",
    "* Vertical lines represents clusters and a joining of vertical lines represents a merging of clusters\n",
    "##### HC with Scipy\n",
    "* Given 'samples'(the array of scores) and 'country names'\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage and dendrogram\n",
    "mergings = linkage(sample, method='complete')  ## its the linkage function that does the HC\n",
    "dendrogram(mergings, labels='country_names', leaf_rotation=90, leaf_font_size=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many merges?\n",
    "If there are 5 data samples, how many merge operations will occur in a hierarchical clustering? To help answer this question, think back to the video, in which Ben walked through an example of hierarchical clustering using 6 countries. How many merge operations did that example have?\n",
    "\n",
    "### Possible Answers\n",
    "4 merges.  ### CORRECT answer\n",
    "\n",
    "5 merges.\n",
    "\n",
    "This can't be known in advance.\n",
    "\n",
    "Well done! With 5 data samples, there would be 4 merge operations, and with 6 data samples, there would be 5 merges, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Hierarchical clustering of the grain data\n",
    "In the video, you learned that the SciPy linkage() function performs hierarchical clustering on an array of samples. Use the linkage() function to obtain a hierarchical clustering of the grain samples, and use dendrogram() to visualize the result. A sample of the grain measurements is provided in the array samples, while the variety of each grain sample is given by the list varieties.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import:\n",
    "linkage and dendrogram from scipy.cluster.hierarchy.\n",
    "matplotlib.pyplot as plt.\n",
    "Perform hierarchical clustering on samples using the linkage() function with the method='complete' keyword argument. Assign the result to mergings.\n",
    "Plot a dendrogram using the dendrogram() function on mergings. Specify the keyword arguments labels=varieties, leaf_rotation=90, and leaf_font_size=6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#samples is a 2D array while varieties is a list\n",
    "samples = np.array([[14.88  , 14.57  ,  0.8811,  5.554 ,  3.333 ,  1.018 ,  4.956 ],\n",
    "       [14.69  , 14.49  ,  0.8799,  5.563 ,  3.259 ,  3.586 ,  5.219 ],\n",
    "       [14.03  , 14.16  ,  0.8796,  5.438 ,  3.201 ,  1.717 ,  5.001 ],\n",
    "       [13.99  , 13.83  ,  0.9183,  5.119 ,  3.383 ,  5.234 ,  4.781 ],\n",
    "       [14.11  , 14.26  ,  0.8722,  5.52  ,  3.168 ,  2.688 ,  5.219 ],\n",
    "       [13.02  , 13.76  ,  0.8641,  5.395 ,  3.026 ,  3.373 ,  4.825 ],\n",
    "       [15.49  , 14.94  ,  0.8724,  5.757 ,  3.371 ,  3.412 ,  5.228 ],\n",
    "       [16.2   , 15.27  ,  0.8734,  5.826 ,  3.464 ,  2.823 ,  5.527 ],\n",
    "       [13.5   , 13.85  ,  0.8852,  5.351 ,  3.158 ,  2.249 ,  5.176 ],\n",
    "       [15.36  , 14.76  ,  0.8861,  5.701 ,  3.393 ,  1.367 ,  5.132 ],\n",
    "       [15.78  , 14.91  ,  0.8923,  5.674 ,  3.434 ,  5.593 ,  5.136 ],\n",
    "       [14.46  , 14.35  ,  0.8818,  5.388 ,  3.377 ,  2.802 ,  5.044 ],\n",
    "       [11.23  , 12.63  ,  0.884 ,  4.902 ,  2.879 ,  2.269 ,  4.703 ],\n",
    "       [14.34  , 14.37  ,  0.8726,  5.63  ,  3.19  ,  1.313 ,  5.15  ],\n",
    "       [16.84  , 15.67  ,  0.8623,  5.998 ,  3.484 ,  4.675 ,  5.877 ],\n",
    "       [17.32  , 15.91  ,  0.8599,  6.064 ,  3.403 ,  3.824 ,  5.922 ],\n",
    "       [18.72  , 16.19  ,  0.8977,  6.006 ,  3.857 ,  5.324 ,  5.879 ],\n",
    "       [18.88  , 16.26  ,  0.8969,  6.084 ,  3.764 ,  1.649 ,  6.109 ],\n",
    "       [18.76  , 16.2   ,  0.8984,  6.172 ,  3.796 ,  3.12  ,  6.053 ],\n",
    "       [19.31  , 16.59  ,  0.8815,  6.341 ,  3.81  ,  3.477 ,  6.238 ],\n",
    "       [17.99  , 15.86  ,  0.8992,  5.89  ,  3.694 ,  2.068 ,  5.837 ],\n",
    "       [18.85  , 16.17  ,  0.9056,  6.152 ,  3.806 ,  2.843 ,  6.2   ],\n",
    "       [19.38  , 16.72  ,  0.8716,  6.303 ,  3.791 ,  3.678 ,  5.965 ],\n",
    "       [18.96  , 16.2   ,  0.9077,  6.051 ,  3.897 ,  4.334 ,  5.75  ],\n",
    "       [18.14  , 16.12  ,  0.8772,  6.059 ,  3.563 ,  3.619 ,  6.011 ],\n",
    "       [18.65  , 16.41  ,  0.8698,  6.285 ,  3.594 ,  4.391 ,  6.102 ],\n",
    "       [18.94  , 16.32  ,  0.8942,  6.144 ,  3.825 ,  2.908 ,  5.949 ],\n",
    "       [17.36  , 15.76  ,  0.8785,  6.145 ,  3.574 ,  3.526 ,  5.971 ],\n",
    "       [13.32  , 13.94  ,  0.8613,  5.541 ,  3.073 ,  7.035 ,  5.44  ],\n",
    "       [11.43  , 13.13  ,  0.8335,  5.176 ,  2.719 ,  2.221 ,  5.132 ],\n",
    "       [12.01  , 13.52  ,  0.8249,  5.405 ,  2.776 ,  6.992 ,  5.27  ],\n",
    "       [11.34  , 12.87  ,  0.8596,  5.053 ,  2.849 ,  3.347 ,  5.003 ],\n",
    "       [12.02  , 13.33  ,  0.8503,  5.35  ,  2.81  ,  4.271 ,  5.308 ],\n",
    "       [12.44  , 13.59  ,  0.8462,  5.319 ,  2.897 ,  4.924 ,  5.27  ],\n",
    "       [11.55  , 13.1   ,  0.8455,  5.167 ,  2.845 ,  6.715 ,  4.956 ],\n",
    "       [11.26  , 13.01  ,  0.8355,  5.186 ,  2.71  ,  5.335 ,  5.092 ],\n",
    "       [12.46  , 13.41  ,  0.8706,  5.236 ,  3.017 ,  4.987 ,  5.147 ],\n",
    "       [11.81  , 13.45  ,  0.8198,  5.413 ,  2.716 ,  4.898 ,  5.352 ],\n",
    "       [11.27  , 12.86  ,  0.8563,  5.091 ,  2.804 ,  3.985 ,  5.001 ],\n",
    "       [12.79  , 13.53  ,  0.8786,  5.224 ,  3.054 ,  5.483 ,  4.958 ],\n",
    "       [12.67  , 13.32  ,  0.8977,  4.984 ,  3.135 ,  2.3   ,  4.745 ],\n",
    "       [11.23  , 12.88  ,  0.8511,  5.14  ,  2.795 ,  4.325 ,  5.003 ]])\n",
    "\n",
    "varieties = ['Kama wheat',\n",
    " 'Kama wheat',\n",
    " 'Kama wheat',\n",
    " 'Kama wheat',\n",
    " 'Kama wheat',\n",
    " 'Kama wheat',\n",
    " 'Kama wheat',\n",
    " 'Kama wheat',\n",
    " 'Kama wheat',\n",
    " 'Kama wheat',\n",
    " 'Kama wheat',\n",
    " 'Kama wheat',\n",
    " 'Kama wheat',\n",
    " 'Kama wheat',\n",
    " 'Rosa wheat',\n",
    " 'Rosa wheat',\n",
    " 'Rosa wheat',\n",
    " 'Rosa wheat',\n",
    " 'Rosa wheat',\n",
    " 'Rosa wheat',\n",
    " 'Rosa wheat',\n",
    " 'Rosa wheat',\n",
    " 'Rosa wheat',\n",
    " 'Rosa wheat',\n",
    " 'Rosa wheat',\n",
    " 'Rosa wheat',\n",
    " 'Rosa wheat',\n",
    " 'Rosa wheat',\n",
    " 'Canadian wheat',\n",
    " 'Canadian wheat',\n",
    " 'Canadian wheat',\n",
    " 'Canadian wheat',\n",
    " 'Canadian wheat',\n",
    " 'Canadian wheat',\n",
    " 'Canadian wheat',\n",
    " 'Canadian wheat',\n",
    " 'Canadian wheat',\n",
    " 'Canadian wheat',\n",
    " 'Canadian wheat',\n",
    " 'Canadian wheat',\n",
    " 'Canadian wheat',\n",
    " 'Canadian wheat']\n",
    "\n",
    "# Perform the necessary imports\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the linkage: mergings\n",
    "mergings = linkage(samples, method='complete')\n",
    "\n",
    "# Plot the dendrogram, using varieties as labels\n",
    "dendrogram(mergings,\n",
    "           labels=varieties,\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=6,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Superb! Dendrograms are a great way to illustrate the arrangement of the clusters produced by hierarchical clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Hierarchies of stocks\n",
    "In chapter 1, you used k-means clustering to cluster companies according to their stock price movements. Now, you'll perform hierarchical clustering of the companies. You are given a NumPy array of price movements movements, where the rows correspond to companies, and a list of the company names companies. \n",
    "##### SciPy hierarchical clustering doesn't fit into a sklearn pipeline, so you'll need to use the normalize() function from sklearn.preprocessing instead of Normalizer. \n",
    "\n",
    "linkage and dendrogram have already been imported from scipy.cluster.hierarchy, and PyPlot has been imported as plt.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import normalize from sklearn.preprocessing.\n",
    "Rescale the price movements for each stock by using the normalize() function on movements.\n",
    "Apply the linkage() function to normalized_movements, using 'complete' linkage, to calculate the hierarchical clustering. Assign the result to mergings.\n",
    "Plot a dendrogram of the hierarchical clustering, using the list companies of company names as the labels. In addition, specify the leaf_rotation=90, and leaf_font_size=6 keyword arguments as you did in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import normalize\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Normalize the movements: normalized_movements\n",
    "normalized_movements = normalize(movements)\n",
    "\n",
    "# Calculate the linkage: mergings\n",
    "mergings = linkage(normalized_movements, method='complete')\n",
    "\n",
    "# Plot the dendrogram\n",
    "dendrogram(mergings, \n",
    "           labels = companies, \n",
    "           leaf_rotation=90, \n",
    "           leaf_font_size =6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! You can produce great visualizations such as this with hierarchical clustering, but it can be used for more than just visualizations. You'll find out more about this in the next video!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster labels in HC\n",
    "* HC is not only a visualization tool\n",
    "* Cluster labels (CL) can be extracted/recovered from intermediate stages of HC\n",
    "* These CL can then be used for further computations eg. cross-tabulations\n",
    "##### Dendrogram (D) show cluster distances\n",
    "* Height of D = distance between merging clusters\n",
    "##### Intermediate Clustering and height of Dendrogram\n",
    "* Height of D specifies max. distance between merging clusters\n",
    "* Dont merge clusters further apart than this\n",
    "##### Distance between clusters\n",
    "* Is defined by 'linkage method'\n",
    "* In 'complete' linkage: distance between clusters is max. distance between their samples  \n",
    "* Specified via method parameter e.g. linkage(samples, method= 'complete')\n",
    "* Different linkage methods, different HC\n",
    "##### Extracting cluster labels\n",
    "* Use the fcluster() function\n",
    "* Returns a numPy array of cluster labels\n",
    "##### Extracting cluster labels using fcluster()\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "mergings = linkage(sample, method ='complete')\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "labels = fcluster(mergings, 15, criterion = 'distance')\n",
    "print(labels)\n",
    "##### Aligning cluster labels with country names\n",
    "Given a list of strings country_names:\n",
    "    import pandas as pd\n",
    "    pairs = pd.DataFrame({'labels': labels, 'countries': country_names})\n",
    "    print(pairs.sort_values(labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which clusters are closest?\n",
    "In the video, you learned that the linkage method defines how the distance between clusters is measured. In complete linkage, the distance between clusters is the distance between the furthest points of the clusters. In single linkage, the distance between clusters is the distance between the closest points of the clusters.\n",
    "\n",
    "Consider the three clusters in the diagram. Which of the following statements are true?\n",
    "\n",
    "\n",
    "\n",
    "A. In single linkage, Cluster 3 is the closest to Cluster 2.\n",
    "\n",
    "B. In complete linkage, Cluster 1 is the closest to Cluster 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER is Both A and B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Different linkage, different hierarchical clustering!\n",
    "In the video, you saw a hierarchical clustering of the voting countries at the Eurovision song contest using 'complete' linkage. Now, perform a hierarchical clustering of the voting countries with 'single' linkage, and compare the resulting dendrogram with the one in the video. Different linkage, different hierarchical clustering!\n",
    "\n",
    "You are given an array samples. Each row corresponds to a voting country, and each column corresponds to a performance that was voted for. The list country_names gives the name of each voting country. This dataset was obtained from Eurovision.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import linkage and dendrogram from scipy.cluster.hierarchy.\n",
    "Perform hierarchical clustering on samples using the linkage() function with the method='single' keyword argument. Assign the result to mergings.\n",
    "Plot a dendrogram of the hierarchical clustering, using the list country_names as the labels. In addition, specify the leaf_rotation=90, and leaf_font_size=6 keyword arguments as you have done earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# Calculate the linkage: mergings\n",
    "mergings = linkage(samples, method='single')\n",
    "\n",
    "# Plot the dendrogram\n",
    "dendrogram(mergings,\n",
    "labels = country_names,\n",
    "leaf_rotation= 90,\n",
    "leaf_font_size=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! As you can see, performing single linkage hierarchical clustering produces a different dendrogram!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Intermediate clusterings\n",
    "Displayed on the right is the dendrogram for the hierarchical clustering of the grain samples that you computed earlier. If the hierarchical clustering were stopped at height 6 on the dendrogram, how many clusters would there be?\n",
    "\n",
    "ANSWER IS 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Extracting the cluster labels\n",
    "In the previous exercise, you saw that the intermediate clustering of the grain samples at height 6 has 3 clusters. Now, use the fcluster() function to extract the cluster labels for this intermediate clustering, and compare the labels with the grain varieties using a cross-tabulation.\n",
    "\n",
    "The hierarchical clustering has already been performed and mergings is the result of the linkage() function. The list varieties gives the variety of each grain sample.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import:\n",
    "pandas as pd.\n",
    "fcluster from scipy.cluster.hierarchy.\n",
    "Perform a flat hierarchical clustering by using the fcluster() function on mergings. Specify a maximum height of 6 and the keyword argument criterion='distance'.\n",
    "Create a DataFrame df with two columns named 'labels' and 'varieties', using labels and varieties, respectively, for the column values. This has been done for you.\n",
    "Create a cross-tabulation ct between df['labels'] and df['varieties'] to count the number of times each grain variety coincides with each cluster label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "import pandas as pd\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "# Use fcluster to extract labels: labels\n",
    "labels = fcluster(mergings, 6, criterion='distance')\n",
    "\n",
    "# Create a DataFrame with labels and varieties as columns: df\n",
    "df = pd.DataFrame({'labels': labels, 'varieties': varieties})\n",
    "\n",
    "# Create crosstab: ct\n",
    "ct = pd.crosstab(df['labels'], df['varieties'])\n",
    "\n",
    "# Display ct\n",
    "print(ct)\n",
    "\n",
    "OUT:\n",
    "varieties  Canadian wheat  Kama wheat  Rosa wheat\n",
    "labels                                           \n",
    "1                      14           3           0\n",
    "2                       0           0          14\n",
    "3                       0          11           0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic - you've now mastered the fundamentals of k-Means and agglomerative hierarchical clustering. Next, you'll learn about t-SNE, which is a powerful tool for visualizing high dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### t-SNE visualization of grain dataset\n",
    "In the video, you saw t-SNE applied to the iris dataset. In this exercise, you'll apply t-SNE to the grain samples data and inspect the resulting t-SNE features using a scatter plot. You are given an array samples of grain samples and a list variety_numbers giving the variety number of each grain sample.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Import TSNE from sklearn.manifold.\n",
    "Create a TSNE instance called model with learning_rate=200.\n",
    "Apply the .fit_transform() method of model to samples. Assign the result to tsne_features.\n",
    "Select the column 0 of tsne_features. Assign the result to xs.\n",
    "Select the column 1 of tsne_features. Assign the result to ys.\n",
    "Make a scatter plot of the t-SNE features xs and ys. To color the points by the grain variety, specify the additional keyword argument c=variety_numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Create a TSNE instance: model\n",
    "model = TSNE(learning_rate=200)\n",
    "\n",
    "# Apply fit_transform to samples: tsne_features\n",
    "tsne_features = model.fit_transform(samples)\n",
    "\n",
    "# Select the 0th feature: xs\n",
    "xs = tsne_features[:,0]\n",
    "\n",
    "# Select the 1st feature: ys\n",
    "ys = tsne_features[:,1]\n",
    "\n",
    "# Scatter plot, coloring by variety_numbers\n",
    "plt.scatter(xs, ys, c=variety_numbers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! As you can see, the t-SNE visualization manages to separate the 3 varieties of grain samples. But how will it perform on the stock data? You'll find out in the next exercise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### A t-SNE map of the stock market\n",
    "t-SNE provides great visualizations when the individual samples can be labeled. In this exercise, you'll apply t-SNE to the company stock price data. A scatter plot of the resulting t-SNE features, labeled by the company names, gives you a map of the stock market! The stock price movements for each company are available as the array normalized_movements (these have already been normalized for you). The list companies gives the name of each company. PyPlot (plt) has been imported for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import TSNE from sklearn.manifold.\n",
    "Create a TSNE instance called model with learning_rate=50.\n",
    "Apply the .fit_transform() method of model to normalized_movements. Assign the result to tsne_features.\n",
    "Select column 0 and column 1 of tsne_features.\n",
    "Make a scatter plot of the t-SNE features xs and ys. Specify the additional keyword argument alpha=0.5.\n",
    "Code to label each point with its company name has been written for you using plt.annotate(), so just hit 'Submit Answer' to see the visualization!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Create a TSNE instance: model\n",
    "model = TSNE(learning_rate=50)\n",
    "\n",
    "# Apply fit_transform to normalized_movements: tsne_features\n",
    "tsne_features = model.fit_transform(normalized_movements)\n",
    "\n",
    "# Select the 0th feature: xs\n",
    "xs = tsne_features[:,0]\n",
    "\n",
    "# Select the 1th feature: ys\n",
    "ys = tsne_features[:,1]\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(xs,ys,alpha=0.5)\n",
    "\n",
    "# Annotate the points\n",
    "for x, y, company in zip(xs, ys, companies):\n",
    "    plt.annotate(company, (x, y), fontsize=5, alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! It's visualizations such as this that make t-SNE such a powerful tool for extracting quick insights from high dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Correlated data in nature\n",
    "You are given an array grains giving the width and length of samples of grain. You suspect that width and length will be correlated. To confirm this, make a scatter plot of width vs length and measure their Pearson correlation.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import:\n",
    "matplotlib.pyplot as plt.\n",
    "pearsonr from scipy.stats.\n",
    "Assign column 0 of grains to width and column 1 of grains to length.\n",
    "Make a scatter plot with width on the x-axis and length on the y-axis.\n",
    "Use the pearsonr() function to calculate the Pearson correlation of width and length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-10-bdb5c045ad94>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-bdb5c045ad94>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    [3.312, 5.763]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "[3.312, 5.763]\n",
    "[3.333, 5.554]\n",
    "[3.337, 5.291]\n",
    "[3.379, 5.324]\n",
    "[3.562, 5.658]\n",
    "[3.312, 5.386]\n",
    "[3.259, 5.563]\n",
    "[3.302, 5.42 ]\n",
    "[3.465, 6.053]\n",
    "[3.505, 5.884]\n",
    "[3.242, 5.714]\n",
    "[3.201, 5.438]\n",
    "[3.199, 5.439]\n",
    "[3.156, 5.479]\n",
    "[3.114, 5.482]\n",
    "[3.333, 5.351]\n",
    " [3.383, 5.119]\n",
    " [3.514, 5.527]\n",
    " [3.466, 5.205]\n",
    " [3.049, 5.226]\n",
    " [3.129, 5.658]\n",
    " [3.168, 5.52 ]\n",
    " [3.507, 5.618]\n",
    " [2.936, 5.099]\n",
    " [3.245, 5.789]\n",
    " [3.421, 5.833]\n",
    " [3.026, 5.395]\n",
    " [2.956, 5.395]\n",
    " [3.221, 5.541]\n",
    " [3.065, 5.516]\n",
    " [2.975, 5.454]\n",
    " [3.371, 5.757]\n",
    " [3.186, 5.717]\n",
    " [3.15 , 5.585]\n",
    " [3.328, 5.712]\n",
    " [3.485, 5.709]\n",
    " [3.464, 5.826]\n",
    " [3.683, 5.832]\n",
    " [3.288, 5.656]\n",
    " [3.298, 5.397]\n",
    " [3.156, 5.348]\n",
    " [3.158, 5.351]\n",
    " [3.201, 5.138]\n",
    " [3.396, 5.877]\n",
    " [3.462, 5.579]\n",
    " [3.155, 5.376]\n",
    " [3.393, 5.701]\n",
    " [3.377, 5.57 ]\n",
    " [3.291, 5.545]\n",
    " [3.258, 5.678]\n",
    " [3.272, 5.585]\n",
    " [3.434, 5.674]\n",
    " [3.113, 5.715]\n",
    " [3.199, 5.504]\n",
    " [3.113, 5.741]\n",
    " [3.212, 5.702]\n",
    " [3.377, 5.388]\n",
    " [3.412, 5.384]\n",
    " [3.419, 5.662]\n",
    " [3.032, 5.159]\n",
    " [2.85 , 5.008]\n",
    " [2.879, 4.902]\n",
    " [3.042, 5.076]\n",
    " [3.07 , 5.395]\n",
    " [3.026, 5.262]\n",
    " [3.119, 5.139]\n",
    " [3.19 , 5.63 ]\n",
    " [3.158, 5.609]\n",
    " [3.153, 5.569]\n",
    " [2.882, 5.412]\n",
    " [3.561, 6.191]\n",
    " [3.484, 5.998]\n",
    " [3.594, 5.978]\n",
    " [3.93 , 6.154]\n",
    " [3.486, 6.017]\n",
    " [3.438, 5.927]\n",
    " [3.403, 6.064]\n",
    " [3.814, 6.579]\n",
    " [3.639, 6.445]\n",
    " [3.566, 5.85 ]\n",
    " [3.467, 5.875]\n",
    " [3.857, 6.006]\n",
    " [3.864, 6.285]\n",
    " [3.772, 6.384]\n",
    " [3.801, 6.366]\n",
    " [3.651, 6.173]\n",
    " [3.764, 6.084]\n",
    " [3.67 , 6.549]\n",
    " [4.033, 6.573]\n",
    " [4.032, 6.45 ]\n",
    " [3.785, 6.581]\n",
    " [3.796, 6.172]\n",
    " [3.693, 6.272]\n",
    " [3.86 , 6.037]\n",
    " [3.485, 6.666]\n",
    " [3.463, 6.139]\n",
    " [3.81 , 6.341]\n",
    " [3.552, 6.449]\n",
    " [3.512, 6.271]\n",
    " [3.684, 6.219]\n",
    " [3.525, 5.718]\n",
    " [3.694, 5.89 ]\n",
    " [3.892, 6.113]\n",
    " [3.681, 6.369]\n",
    " [3.755, 6.248]\n",
    " [3.786, 6.037]\n",
    " [3.806, 6.152]\n",
    " [3.573, 6.033]\n",
    " [3.763, 6.675]\n",
    " [3.674, 6.153]\n",
    " [3.769, 6.107]\n",
    " [3.791, 6.303]\n",
    " [3.902, 6.183]\n",
    " [3.737, 6.259]\n",
    " [3.991, 6.563]\n",
    " [3.719, 6.416]\n",
    " [3.897, 6.051]\n",
    " [3.815, 6.245]\n",
    " [3.769, 6.227]\n",
    " [3.857, 6.493]\n",
    " [3.962, 6.315]\n",
    " [3.563, 6.059]\n",
    " [3.387, 5.762]\n",
    " [3.771, 5.98 ]\n",
    " [3.582, 5.363]\n",
    " [3.869, 6.111]\n",
    " [3.594, 6.285]\n",
    " [3.687, 5.979]\n",
    " [3.773, 6.513]\n",
    " [3.69 , 5.791]\n",
    " [3.755, 5.979]\n",
    " [3.825, 6.144]\n",
    " [3.268, 5.884]\n",
    " [3.395, 5.845]\n",
    " [3.408, 5.776]\n",
    " [3.465, 5.477]\n",
    " [3.574, 6.145]\n",
    " [3.231, 5.92 ]\n",
    " [3.286, 5.832]\n",
    " [3.472, 5.872]\n",
    " [2.994, 5.472]\n",
    " [3.073, 5.541]\n",
    " [3.074, 5.389]\n",
    " [2.967, 5.224]\n",
    " [2.777, 5.314]\n",
    " [2.687, 5.279]\n",
    " [2.719, 5.176]\n",
    " [2.967, 5.267]\n",
    " [2.911, 5.386]\n",
    " [2.648, 5.317]\n",
    " [2.84 , 5.263]\n",
    " [2.776, 5.405]\n",
    " [2.833, 5.408]\n",
    " [2.693, 5.22 ]\n",
    " [2.755, 5.175]\n",
    " [2.675, 5.25 ]\n",
    " [2.849, 5.053]\n",
    " [2.745, 5.394]\n",
    " [2.678, 5.444]\n",
    " [2.695, 5.304]\n",
    " [2.879, 5.451]\n",
    " [2.81 , 5.35 ]\n",
    " [2.847, 5.267]\n",
    " [2.968, 5.333]\n",
    " [2.794, 5.011]\n",
    " [2.941, 5.105]\n",
    " [2.897, 5.319]\n",
    " [2.837, 5.417]\n",
    " [2.668, 5.176]\n",
    " [2.715, 5.09 ]\n",
    " [2.701, 5.325]\n",
    " [2.845, 5.167]\n",
    " [2.763, 5.088]\n",
    " [2.763, 5.136]\n",
    " [2.641, 5.278]\n",
    " [2.821, 4.981]\n",
    " [2.71 , 5.186]\n",
    " [2.642, 5.145]\n",
    " [2.758, 5.18 ]\n",
    " [2.893, 5.357]\n",
    " [2.775, 5.09 ]\n",
    " [3.017, 5.236]\n",
    " [2.909, 5.24 ]\n",
    " [2.85 , 5.108]\n",
    " [3.026, 5.495]\n",
    " [2.683, 5.363]\n",
    " [2.716, 5.413]\n",
    " [2.675, 5.088]\n",
    " [2.821, 5.089]\n",
    " [2.787, 4.899]\n",
    " [2.717, 5.046]\n",
    " [2.804, 5.091]\n",
    " [2.953, 5.132]\n",
    " [2.63 , 5.18 ]\n",
    " [2.975, 5.236]\n",
    " [3.126, 5.16 ]\n",
    " [3.054, 5.224]\n",
    " [3.128, 5.32 ]\n",
    " [2.911, 5.41 ]\n",
    " [3.155, 5.073]\n",
    " [2.989, 5.219]\n",
    " [3.135, 4.984]\n",
    " [2.81 , 5.009]\n",
    " [3.091, 5.183]\n",
    " [2.96 , 5.204]\n",
    " [2.981, 5.137]\n",
    " [2.795, 5.14 ]\n",
    " [3.232, 5.236]\n",
    " [2.836, 5.175]\n",
    " [2.974, 5.243]\n",
    "grains = np.array(grain)\n",
    "\n",
    "# Perform the necessary imports\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "# Assign the 0th column of grains: width\n",
    "width = grains[:,0]\n",
    "\n",
    "# Assign the 1st column of grains: length\n",
    "length = grains[:,1]\n",
    "\n",
    "# Scatter plot width vs length\n",
    "plt.scatter(width, length)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the Pearson correlation\n",
    "correlation, pvalue = pearsonr(width, length)\n",
    "\n",
    "# Display the correlation\n",
    "print(correlation)\n",
    "OUT:\n",
    "    0.8604149377143466"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! As you would expect, the width and length of the grain samples are highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Decorrelating the grain measurements with PCA\n",
    "You observed in the previous exercise that the width and length measurements of the grain are correlated. Now, you'll use PCA to decorrelate these measurements, then plot the decorrelated points and measure their Pearson correlation.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import PCA from sklearn.decomposition.\n",
    "Create an instance of PCA called model.\n",
    "Use the .fit_transform() method of model to apply the PCA transformation to grains. Assign the result to pca_features.\n",
    "The subsequent code to extract, plot, and compute the Pearson correlation of the first two columns pca_features has been written for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-1022b798dd68>, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-1022b798dd68>\"\u001b[1;36m, line \u001b[1;32m27\u001b[0m\n\u001b[1;33m    OUT:\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create PCA instance: model\n",
    "model = PCA()\n",
    "\n",
    "# Apply the fit_transform method of model to grains: pca_features\n",
    "pca_features = model.fit_transform(grains)\n",
    "\n",
    "# Assign 0th column of pca_features: xs\n",
    "xs = pca_features[:,0]\n",
    "\n",
    "# Assign 1st column of pca_features: ys\n",
    "ys = pca_features[:,1]\n",
    "\n",
    "# Scatter plot xs vs ys\n",
    "plt.scatter(xs, ys)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the Pearson correlation of xs and ys\n",
    "correlation, pvalue = pearsonr(xs, ys)\n",
    "\n",
    "# Display the correlation\n",
    "print(correlation)\n",
    "\n",
    "OUT:\n",
    "    2.5478751053409354e-17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! You've successfully decorrelated the grain measurements with PCA!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Principal components\n",
    "On the right are three scatter plots of the same point cloud. Each scatter plot shows a different set of axes (in red). In which of the plots could the axes represent the principal components of the point cloud?\n",
    "\n",
    "ANSWER IS 1 and 3\n",
    "\n",
    "Recall that the principal components are the directions along which the the data varies.Well done! You've correctly inferred that the principal components have to align with the axes of the point cloud. This happens in both plot 1 and plot 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scatter plot of the untransformed points\n",
    "plt.scatter(grains[:,0], grains[:,1])\n",
    "\n",
    "# Create a PCA instance: model\n",
    "model = PCA()\n",
    "\n",
    "# Fit model to points\n",
    "model.fit(grains)\n",
    "\n",
    "# Get the mean of the grain samples: mean\n",
    "mean = model.mean_\n",
    "\n",
    "# Get the first principal component: first_pc\n",
    "first_pc = model.components_[0,:]\n",
    "\n",
    "# Plot first_pc as an arrow, starting at mean\n",
    "plt.arrow(mean[0], mean[1], first_pc[0], first_pc[1], color='red', width=0.01)\n",
    "\n",
    "# Keep axes on same scale\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent job! This is the direction in which the grain data varies the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Variance of the PCA features\n",
    "The fish dataset is 6-dimensional. But what is its intrinsic dimension? Make a plot of the variances of the PCA features to find out. As before, samples is a 2D array, where each row represents a fish. You'll need to standardize the features first.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Create an instance of StandardScaler called scaler.\n",
    "Create a PCA instance called pca.\n",
    "Use the make_pipeline() function to create a pipeline chaining scaler and pca.\n",
    "Use the .fit() method of pipeline to fit it to the fish samples samples.\n",
    "Extract the number of components used using the .n_components_ attribute of pca. Place this inside a range() function and store the result as features.\n",
    "Use the plt.bar() function to plot the explained variances, with features on the x-axis and pca.explained_variance_ on the y-axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " [[ 242.    23.2   25.4   30.    38.4   13.4]\n",
    " [ 290.    24.    26.3   31.2   40.    13.8]\n",
    " [ 340.    23.9   26.5   31.1   39.8   15.1]\n",
    " [ 363.    26.3   29.    33.5   38.    13.3]\n",
    " [ 430.    26.5   29.    34.    36.6   15.1]\n",
    " [ 450.    26.8   29.7   34.7   39.2   14.2]\n",
    " [ 500.    26.8   29.7   34.5   41.1   15.3]\n",
    " [ 390.    27.6   30.    35.    36.2   13.4]\n",
    " [ 450.    27.6   30.    35.1   39.9   13.8]\n",
    " [ 500.    28.5   30.7   36.2   39.3   13.7]\n",
    " [ 475.    28.4   31.    36.2   39.4   14.1]\n",
    " [ 500.    28.7   31.    36.2   39.7   13.3]\n",
    " [ 500.    29.1   31.5   36.4   37.8   12. ]\n",
    " [ 600.    29.4   32.    37.2   40.2   13.9]\n",
    " [ 600.    29.4   32.    37.2   41.5   15. ]\n",
    " [ 700.    30.4   33.    38.3   38.8   13.8]\n",
    " [ 700.    30.4   33.    38.5   38.8   13.5]\n",
    " [ 610.    30.9   33.5   38.6   40.5   13.3]\n",
    " [ 650.    31.    33.5   38.7   37.4   14.8]\n",
    " [ 575.    31.3   34.    39.5   38.3   14.1]\n",
    " [ 685.    31.4   34.    39.2   40.8   13.7]\n",
    " [ 620.    31.5   34.5   39.7   39.1   13.3]\n",
    " [ 680.    31.8   35.    40.6   38.1   15.1]\n",
    " [ 700.    31.9   35.    40.5   40.1   13.8]\n",
    " [ 725.    31.8   35.    40.9   40.    14.8]\n",
    " [ 720.    32.    35.    40.6   40.3   15. ]\n",
    " [ 714.    32.7   36.    41.5   39.8   14.1]\n",
    " [ 850.    32.8   36.    41.6   40.6   14.9]\n",
    " [1000.    33.5   37.    42.6   44.5   15.5]\n",
    " [ 920.    35.    38.5   44.1   40.9   14.3]\n",
    " [ 955.    35.    38.5   44.    41.1   14.3]\n",
    " [ 925.    36.2   39.5   45.3   41.4   14.9]\n",
    " [ 975.    37.4   41.    45.9   40.6   14.7]\n",
    " [ 950.    38.    41.    46.5   37.9   13.7]\n",
    " [  40.    12.9   14.1   16.2   25.6   14. ]\n",
    " [  69.    16.5   18.2   20.3   26.1   13.9]\n",
    " [  78.    17.5   18.8   21.2   26.3   13.7]\n",
    " [  87.    18.2   19.8   22.2   25.3   14.3]\n",
    " [ 120.    18.6   20.    22.2   28.    16.1]\n",
    " [   0.    19.    20.5   22.8   28.4   14.7]\n",
    " [ 110.    19.1   20.8   23.1   26.7   14.7]\n",
    " [ 120.    19.4   21.    23.7   25.8   13.9]\n",
    " [ 150.    20.4   22.    24.7   23.5   15.2]\n",
    " [ 145.    20.5   22.    24.3   27.3   14.6]\n",
    " [ 160.    20.5   22.5   25.3   27.8   15.1]\n",
    " [ 140.    21.    22.5   25.    26.2   13.3]\n",
    " [ 160.    21.1   22.5   25.    25.6   15.2]\n",
    " [ 169.    22.    24.    27.2   27.7   14.1]\n",
    " [ 161.    22.    23.4   26.7   25.9   13.6]\n",
    " [ 200.    22.1   23.5   26.8   27.6   15.4]\n",
    " [ 180.    23.6   25.2   27.9   25.4   14. ]\n",
    " [ 290.    24.    26.    29.2   30.4   15.4]\n",
    " [ 272.    25.    27.    30.6   28.    15.6]\n",
    " [ 390.    29.5   31.7   35.    27.1   15.3]\n",
    " [   6.7    9.3    9.8   10.8   16.1    9.7]\n",
    " [   7.5   10.    10.5   11.6   17.    10. ]\n",
    " [   7.    10.1   10.6   11.6   14.9    9.9]\n",
    " [   9.7   10.4   11.    12.    18.3   11.5]\n",
    " [   9.8   10.7   11.2   12.4   16.8   10.3]\n",
    " [   8.7   10.8   11.3   12.6   15.7   10.2]\n",
    " [  10.    11.3   11.8   13.1   16.9    9.8]\n",
    " [   9.9   11.3   11.8   13.1   16.9    8.9]\n",
    " [   9.8   11.4   12.    13.2   16.7    8.7]\n",
    " [  12.2   11.5   12.2   13.4   15.6   10.4]\n",
    " [  13.4   11.7   12.4   13.5   18.     9.4]\n",
    " [  12.2   12.1   13.    13.8   16.5    9.1]\n",
    " [  19.7   13.2   14.3   15.2   18.9   13.6]\n",
    " [  19.9   13.8   15.    16.2   18.1   11.6]\n",
    " [ 200.    30.    32.3   34.8   16.     9.7]\n",
    " [ 300.    31.7   34.    37.8   15.1   11. ]\n",
    " [ 300.    32.7   35.    38.8   15.3   11.3]\n",
    " [ 300.    34.8   37.3   39.8   15.8   10.1]\n",
    " [ 430.    35.5   38.    40.5   18.    11.3]\n",
    " [ 345.    36.    38.5   41.    15.6    9.7]\n",
    " [ 456.    40.    42.5   45.5   16.     9.5]\n",
    " [ 510.    40.    42.5   45.5   15.     9.8]\n",
    " [ 540.    40.1   43.    45.8   17.    11.2]\n",
    " [ 500.    42.    45.    48.    14.5   10.2]\n",
    " [ 567.    43.2   46.    48.7   16.    10. ]\n",
    " [ 770.    44.8   48.    51.2   15.    10.5]\n",
    " [ 950.    48.3   51.7   55.1   16.2   11.2]\n",
    " [1250.    52.    56.    59.7   17.9   11.7]\n",
    " [1600.    56.    60.    64.    15.     9.6]\n",
    " [1550.    56.    60.    64.    15.     9.6]\n",
    " [1650.    59.    63.4   68.    15.9   11. ]]\n",
    "\n",
    "# Perform the necessary imports\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create scaler: scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a PCA instance: pca\n",
    "pca = PCA()\n",
    "\n",
    "# Create pipeline: pipeline\n",
    "pipeline = make_pipeline(scaler, pca)\n",
    "\n",
    "# Fit the pipeline to 'samples'\n",
    "pipeline.fit(samples)\n",
    "\n",
    "# Plot the explained variances\n",
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_)\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('variance')\n",
    "plt.xticks(features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! It looks like PCA features 0 and 1 have significant variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Intrinsic dimension of the fish data\n",
    "In the previous exercise, you plotted the variance of the PCA features of the fish measurements. Looking again at your plot, what do you think would be a reasonable choice for the \"intrinsic dimension\" of the the fish measurements? Recall that the intrinsic dimension is the number of PCA features with significant variance.\n",
    "\n",
    "ANSWER IS 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! Since PCA features 0 and 1 have significant variance, the intrinsic dimension of this dataset appears to be 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Dimension reduction of the fish measurements\n",
    "In a previous exercise, you saw that 2 was a reasonable choice for the \"intrinsic dimension\" of the fish measurements. Now use PCA for dimensionality reduction of the fish measurements, retaining only the 2 most important components.\n",
    "\n",
    "The fish measurements have already been scaled for you, and are available as scaled_samples.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import PCA from sklearn.decomposition.\n",
    "Create a PCA instance called pca with n_components=2.\n",
    "Use the .fit() method of pca to fit it to the scaled fish measurements scaled_samples.\n",
    "Use the .transform() method of pca to transform the scaled_samples. Assign the result to pca_features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[-0.50109735 -0.36878558 -0.34323399 -0.23781518  1.0032125   0.25373964]\n",
    " [-0.37434344 -0.29750241 -0.26893461 -0.14634781  1.15869615  0.44376493]\n",
    " [-0.24230812 -0.30641281 -0.25242364 -0.15397009  1.13926069  1.0613471 ]\n",
    " [-0.18157187 -0.09256329 -0.04603648  0.02896467  0.96434159  0.20623332]\n",
    " [-0.00464454 -0.0747425  -0.04603648  0.06707608  0.8282934   1.0613471 ]\n",
    " [ 0.04816959 -0.04801131  0.01175193  0.12043205  1.08095432  0.63379021]\n",
    " [ 0.18020491 -0.04801131  0.01175193  0.10518748  1.26559115  1.15635974]\n",
    " [-0.11027279  0.02327186  0.03651839  0.14329889  0.78942248  0.25373964]\n",
    " [ 0.04816959  0.02327186  0.03651839  0.15092117  1.14897842  0.44376493]\n",
    " [ 0.18020491  0.10346543  0.09430679  0.23476627  1.09067205  0.39625861]\n",
    " [ 0.11418725  0.09455503  0.11907325  0.23476627  1.10038978  0.58628389]\n",
    " [ 0.18020491  0.12128622  0.11907325  0.23476627  1.12954296  0.20623332]\n",
    " [ 0.18020491  0.1569278   0.16035069  0.25001083  0.94490613 -0.41134885]\n",
    " [ 0.44427556  0.18365899  0.20162812  0.31098909  1.1781316   0.49127125]\n",
    " [ 0.44427556  0.18365899  0.20162812  0.31098909  1.30446206  1.01384078]\n",
    " [ 0.7083462   0.27276296  0.28418298  0.39483418  1.04208341  0.44376493]\n",
    " [ 0.7083462   0.27276296  0.28418298  0.41007875  1.04208341  0.30124596]\n",
    " [ 0.47068262  0.31731494  0.32546042  0.41770103  1.20728478  0.20623332]\n",
    " [ 0.57631088  0.32622533  0.32546042  0.42532331  0.90603522  0.91882813]\n",
    " [ 0.3782579   0.35295652  0.36673785  0.48630156  0.99349477  0.58628389]\n",
    " [ 0.66873561  0.36186692  0.36673785  0.46343472  1.23643797  0.39625861]\n",
    " [ 0.49708969  0.37077732  0.40801528  0.50154612  1.07123659  0.20623332]\n",
    " [ 0.65553208  0.3975085   0.44929271  0.57014666  0.97405931  1.0613471 ]\n",
    " [ 0.7083462   0.4064189   0.44929271  0.56252438  1.16841387  0.44376493]\n",
    " [ 0.77436387  0.3975085   0.44929271  0.5930135   1.15869615  0.91882813]\n",
    " [ 0.76116033  0.4153293   0.44929271  0.57014666  1.18784933  1.01384078]\n",
    " [ 0.74531609  0.47770207  0.53184758  0.63874719  1.13926069  0.58628389]\n",
    " [ 1.10445217  0.48661247  0.53184758  0.64636947  1.21700251  0.96633446]\n",
    " [ 1.50055814  0.54898524  0.61440245  0.72259229  1.5959939   1.25137238]\n",
    " [ 1.28930162  0.68264119  0.73823474  0.83692651  1.2461557   0.68129653]\n",
    " [ 1.38172635  0.68264119  0.73823474  0.82930423  1.26559115  0.68129653]\n",
    " [ 1.30250516  0.78956594  0.82078961  0.92839389  1.29474434  0.96633446]\n",
    " [ 1.43454048  0.8964907   0.94462191  0.97412758  1.21700251  0.87132181]\n",
    " [ 1.36852282  0.94995308  0.94462191  1.01986127  0.95462386  0.39625861]\n",
    " [-1.03452005 -1.2865564  -1.27610397 -1.28969003 -0.24065667  0.53877757]\n",
    " [-0.95793956 -0.96578213 -0.93762902 -0.97717649 -0.19206803  0.49127125]\n",
    " [-0.93417321 -0.87667817 -0.8880961  -0.90857596 -0.17263258  0.39625861]\n",
    " [-0.91040685 -0.8143054  -0.80554124 -0.83235314 -0.26980986  0.68129653]\n",
    " [-0.82326354 -0.77866381 -0.78903027 -0.83235314 -0.0074312   1.5364103 ]\n",
    " [-1.14014831 -0.74302223 -0.74775283 -0.78661945  0.03143971  0.87132181]\n",
    " [-0.8496706  -0.73411183 -0.72298637 -0.76375261 -0.13376167  0.87132181]\n",
    " [-0.82326354 -0.70738064 -0.7064754  -0.71801892 -0.22122122  0.49127125]\n",
    " [-0.74404234 -0.61827668 -0.62392054 -0.6417961  -0.44472896  1.10885342]\n",
    " [-0.75724587 -0.60936628 -0.62392054 -0.67228523 -0.0754553   0.82381549]\n",
    " [-0.71763528 -0.60936628 -0.5826431  -0.59606241 -0.02686666  1.0613471 ]\n",
    " [-0.77044941 -0.5648143  -0.5826431  -0.61892926 -0.18235031  0.20623332]\n",
    " [-0.71763528 -0.5559039  -0.5826431  -0.61892926 -0.24065667  1.10885342]\n",
    " [-0.69386892 -0.47571034 -0.4588108  -0.45123907 -0.03658439  0.58628389]\n",
    " [-0.71499457 -0.47571034 -0.50834372 -0.48935047 -0.21150349  0.34875228]\n",
    " [-0.61200702 -0.46679994 -0.50008824 -0.48172819 -0.04630212  1.20386606]\n",
    " [-0.66482115 -0.33314399 -0.35974497 -0.39788309 -0.26009213  0.53877757]\n",
    " [-0.37434344 -0.29750241 -0.29370107 -0.29879344  0.22579427  1.20386606]\n",
    " [-0.42187616 -0.20839845 -0.21114621 -0.19208149 -0.0074312   1.2988787 ]\n",
    " [-0.11027279  0.19256939  0.17686166  0.14329889 -0.09489075  1.15635974]\n",
    " [-1.12245558 -1.60733067 -1.63108989 -1.70129323 -1.16384082 -1.50399423]\n",
    " [-1.12034301 -1.5449579  -1.57330149 -1.64031498 -1.07638127 -1.36147526]\n",
    " [-1.12166336 -1.5360475  -1.565046   -1.64031498 -1.28045356 -1.40898159]\n",
    " [-1.11453346 -1.50931631 -1.53202405 -1.60982586 -0.95005081 -0.64888045]\n",
    " [-1.11426939 -1.48258512 -1.51551308 -1.57933673 -1.09581673 -1.2189563 ]\n",
    " [-1.11717416 -1.47367473 -1.5072576  -1.56409217 -1.20271174 -1.26646262]\n",
    " [-1.11374125 -1.42912274 -1.46598016 -1.52598076 -1.086099   -1.45648791]\n",
    " [-1.11400532 -1.42912274 -1.46598016 -1.52598076 -1.086099   -1.88404479]\n",
    " [-1.11426939 -1.42021235 -1.44946919 -1.51835848 -1.10553446 -1.97905744]\n",
    " [-1.10793169 -1.41130195 -1.43295822 -1.50311391 -1.21242946 -1.17144998]\n",
    " [-1.10476284 -1.39348116 -1.41644724 -1.49549163 -0.97920399 -1.64651319]\n",
    " [-1.10793169 -1.35783957 -1.36691432 -1.47262479 -1.12496991 -1.78903215]\n",
    " [-1.08812639 -1.25982521 -1.259593   -1.36591285 -0.89174444  0.34875228]\n",
    " [-1.08759825 -1.20636284 -1.20180459 -1.28969003 -0.96948627 -0.60137413]\n",
    " [-0.61200702  0.23712137  0.22639458  0.12805433 -1.17355855 -1.50399423]\n",
    " [-0.34793638  0.38859811  0.36673785  0.35672277 -1.2610181  -0.88641206]\n",
    " [-0.34793638  0.47770207  0.44929271  0.43294559 -1.24158265 -0.74389309]\n",
    " [-0.34793638  0.6648204   0.6391689   0.5091684  -1.19299401 -1.31396894]\n",
    " [-0.00464454  0.72719317  0.69695731  0.56252438 -0.97920399 -0.74389309]\n",
    " [-0.22910458  0.77174515  0.73823474  0.60063578 -1.21242946 -1.50399423]\n",
    " [ 0.06401383  1.128161    1.0684542   0.94363845 -1.17355855 -1.59900687]\n",
    " [ 0.20661198  1.128161    1.0684542   0.94363845 -1.27073583 -1.45648791]\n",
    " [ 0.28583317  1.1370714   1.10973164  0.9665053  -1.07638127 -0.79139942]\n",
    " [ 0.18020491  1.30636893  1.27484137  1.13419549 -1.31932447 -1.26646262]\n",
    " [ 0.35713225  1.41329369  1.35739623  1.18755146 -1.17355855 -1.36147526]\n",
    " [ 0.89319566  1.55586003  1.52250596  1.3781085  -1.27073583 -1.12394366]\n",
    " [ 1.36852282  1.8677239   1.82795897  1.67537748 -1.1541231  -0.79139942]\n",
    " [ 2.16073475  2.19740857  2.18294489  2.02600243 -0.98892172 -0.55386781]\n",
    " [ 3.08498201  2.55382442  2.51316435  2.35376053 -1.27073583 -1.55150055]\n",
    " [ 2.95294669  2.55382442  2.51316435  2.35376053 -1.27073583 -1.55150055]\n",
    " [ 3.21701733  2.82113631  2.79385089  2.65865179 -1.18327628 -0.88641206]]\n",
    "\n",
    "# Import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "# Create a PCA model with 2 components: pca\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit the PCA instance to the scaled samples\n",
    "pca.fit(scaled_samples)\n",
    "\n",
    "# Transform the scaled samples: pca_features\n",
    "pca_features = pca.transform(scaled_samples)\n",
    "\n",
    "# Print the shape of pca_features\n",
    "print(pca_features.shape)\n",
    "OUT:\n",
    "    (85, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Superb! You've successfully reduced the dimensionality from 6 to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### A tf-idf word-frequency array\n",
    "In this exercise, you'll create a tf-idf word frequency array for a toy collection of documents. For this, use the TfidfVectorizer from sklearn. It transforms a list of documents into a word frequency array, which it outputs as a csr_matrix. It has fit() and transform() methods like other sklearn objects.\n",
    "\n",
    "You are given a list documents of toy documents about pets. Its contents have been printed in the IPython Shell.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import TfidfVectorizer from sklearn.feature_extraction.text.\n",
    "Create a TfidfVectorizer instance called tfidf.\n",
    "Apply .fit_transform() method of tfidf to documents and assign the result to csr_mat. This is a word-frequency array in csr_matrix format.\n",
    "Inspect csr_mat by calling its .toarray() method and printing the result. This has been done for you.\n",
    "The columns of the array correspond to words. Get the list of words by calling the .get_feature_names() method of tfidf, and assign the result to words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51785612 0.         0.         0.68091856 0.51785612 0.        ]\n",
      " [0.         0.         0.51785612 0.         0.51785612 0.68091856]\n",
      " [0.51785612 0.68091856 0.51785612 0.         0.         0.        ]]\n",
      "['cats', 'chase', 'dogs', 'meow', 'say', 'woof']\n"
     ]
    }
   ],
   "source": [
    "documents = ['cats say meow', 'dogs say woof', 'dogs chase cats']\n",
    "\n",
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a TfidfVectorizer: tfidf\n",
    "tfidf = TfidfVectorizer() \n",
    "\n",
    "# Apply fit_transform to document: csr_mat\n",
    "csr_mat = tfidf.fit_transform(documents)\n",
    "\n",
    "# Print result of toarray() method\n",
    "print(csr_mat.toarray())\n",
    "\n",
    "# Get the words: words\n",
    "words = tfidf.get_feature_names()\n",
    "\n",
    "# Print words\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! You'll now move to clustering Wikipedia articles!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Clustering Wikipedia part I\n",
    "You saw in the video that TruncatedSVD is able to perform PCA on sparse arrays in csr_matrix format, such as word-frequency arrays. Combine your knowledge of TruncatedSVD and k-means to cluster some popular pages from Wikipedia. In this exercise, build the pipeline. In the next exercise, you'll apply it to the word-frequency array of some Wikipedia articles.\n",
    "\n",
    "Create a Pipeline object consisting of a TruncatedSVD followed by KMeans. (This time, we've precomputed the word-frequency matrix for you, so there's no need for a TfidfVectorizer).\n",
    "\n",
    "The Wikipedia dataset you will be working with was obtained from here.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import:\n",
    "TruncatedSVD from sklearn.decomposition.\n",
    "KMeans from sklearn.cluster.\n",
    "make_pipeline from sklearn.pipeline.\n",
    "Create a TruncatedSVD instance called svd with n_components=50.\n",
    "Create a KMeans instance called kmeans with n_clusters=6.\n",
    "Create a pipeline called pipeline consisting of svd and kmeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a TruncatedSVD instance: svd\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "\n",
    "# Create a KMeans instance: kmeans\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "\n",
    "# Create a pipeline: pipeline\n",
    "pipeline = make_pipeline(svd,kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! Now that you have set up your pipeline, you will use it in the next exercise to cluster the articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Clustering Wikipedia part II\n",
    "It is now time to put your pipeline from the previous exercise to work! You are given an array articles of tf-idf word-frequencies of some popular Wikipedia articles, and a list titles of their titles. Use your pipeline to cluster the Wikipedia articles.\n",
    "\n",
    "A solution to the previous exercise has been pre-loaded for you, so a Pipeline pipeline chaining TruncatedSVD with KMeans is available.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import pandas as pd.\n",
    "Fit the pipeline to the word-frequency array articles.\n",
    "Predict the cluster labels.\n",
    "Align the cluster labels with the list titles of article titles by creating a DataFrame df with labels and titles as columns. This has been done for you.\n",
    "Use the .sort_values() method of df to sort the DataFrame by the 'label' column, and print the result.\n",
    "Hit 'Submit Answer' and take a moment to investigate your amazing clustering of Wikipedia pages!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Fit the pipeline to articles\n",
    "pipeline.fit(articles)\n",
    "\n",
    "# Calculate the cluster labels: labels\n",
    "labels = pipeline.predict(articles)\n",
    "\n",
    "# Create a DataFrame aligning labels and titles: df\n",
    "df = pd.DataFrame({'label': labels, 'article': titles})\n",
    "\n",
    "# Display df sorted by cluster label\n",
    "print(df.sort_values('label'))\n",
    "\n",
    "OUT:\n",
    "    label                                        article\n",
    "59      0                                    Adam Levine\n",
    "57      0                          Red Hot Chili Peppers\n",
    "56      0                                       Skrillex\n",
    "55      0                                  Black Sabbath\n",
    "54      0                                 Arctic Monkeys\n",
    "53      0                                   Stevie Nicks\n",
    "52      0                                     The Wanted\n",
    "51      0                                     Nate Ruess\n",
    "50      0                                   Chad Kroeger\n",
    "58      0                                         Sepsis\n",
    "30      1                  France national football team\n",
    "31      1                              Cristiano Ronaldo\n",
    "32      1                                   Arsenal F.C.\n",
    "33      1                                 Radamel Falcao\n",
    "37      1                                       Football\n",
    "35      1                Colombia national football team\n",
    "36      1              2014 FIFA World Cup qualification\n",
    "38      1                                         Neymar\n",
    "39      1                                  Franck Ribry\n",
    "34      1                             Zlatan Ibrahimovi\n",
    "26      2                                     Mila Kunis\n",
    "28      2                                  Anne Hathaway\n",
    "27      2                                 Dakota Fanning\n",
    "25      2                                  Russell Crowe\n",
    "29      2                               Jennifer Aniston\n",
    "23      2                           Catherine Zeta-Jones\n",
    "22      2                              Denzel Washington\n",
    "21      2                             Michael Fassbender\n",
    "20      2                                 Angelina Jolie\n",
    "24      2                                   Jessica Biel\n",
    "10      3                                 Global warming\n",
    "11      3       Nationally Appropriate Mitigation Action\n",
    "13      3                               Connie Hedegaard\n",
    "14      3                                 Climate change\n",
    "12      3                                   Nigel Lawson\n",
    "16      3                                        350.org\n",
    "17      3  Greenhouse gas emissions by the United States\n",
    "18      3  2010 United Nations Climate Change Conference\n",
    "19      3  2007 United Nations Climate Change Conference\n",
    "15      3                                 Kyoto Protocol\n",
    "8       4                                        Firefox\n",
    "1       4                                 Alexa Internet\n",
    "2       4                              Internet Explorer\n",
    "3       4                                    HTTP cookie\n",
    "4       4                                  Google Search\n",
    "5       4                                         Tumblr\n",
    "6       4                    Hypertext Transfer Protocol\n",
    "7       4                                  Social search\n",
    "49      4                                       Lymphoma\n",
    "42      4                                    Doxycycline\n",
    "47      4                                          Fever\n",
    "46      4                                     Prednisone\n",
    "44      4                                           Gout\n",
    "43      4                                       Leukemia\n",
    "9       4                                       LinkedIn\n",
    "48      4                                     Gabapentin\n",
    "0       4                                       HTTP 404\n",
    "45      5                                    Hepatitis C\n",
    "41      5                                    Hepatitis B\n",
    "40      5                                    Tonsillitis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! Take a look at the cluster labels and see if you can identify any patterns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-negative data\n",
    "#### Which of the following 2-dimensional arrays are examples of non-negative data?\n",
    "\n",
    "1) A tf-idf word-frequency array.\n",
    "\n",
    "2) An array daily stock market price movements (up and down), where each row represents a company.\n",
    "\n",
    "3) An array where rows are customers, columns are products and entries are 0 or 1, indicating whether a customer has purchased a product.\n",
    "\n",
    "ANSWER IS 1 and 3\n",
    "\n",
    "Well done! Stock prices can go down as well as up, so an array of daily stock market price movements is not an example of non-negative data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### NMF applied to Wikipedia articles\n",
    "In the video, you saw NMF applied to transform a toy word-frequency array. Now it's your turn to apply NMF, this time using the tf-idf word-frequency array of Wikipedia articles, given as a csr matrix articles. Here, fit the model and transform the articles. In the next exercise, you'll explore the result.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import NMF from sklearn.decomposition.\n",
    "Create an NMF instance called model with 6 components.\n",
    "Fit the model to the word count data articles.\n",
    "Use the .transform() method of model to transform articles, and assign the result to nmf_features.\n",
    "Print nmf_features to get a first idea what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NMF\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Create an NMF instance: model\n",
    "model = NMF(n_components=6)\n",
    "\n",
    "# Fit the model to articles\n",
    "model.fit(articles)\n",
    "\n",
    "# Transform the articles: nmf_features\n",
    "nmf_features = model.transform(articles)\n",
    "\n",
    "# Print the NMF features\n",
    "print(nmf_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic - these NMF features don't make much sense at this point, but you will explore them in the next exercise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### NMF features of the Wikipedia articles\n",
    "Now you will explore the NMF features you created in the previous exercise. A solution to the previous exercise has been pre-loaded, so the array nmf_features is available. Also available is a list titles giving the title of each Wikipedia article.\n",
    "\n",
    "When investigating the features, notice that for both actors, the NMF feature 3 has by far the highest value. This means that both articles are reconstructed using mainly the 3rd NMF component. In the next video, you'll see why: NMF components represent topics (for instance, acting!).\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import pandas as pd.\n",
    "Create a DataFrame df from nmf_features using pd.DataFrame(). Set the index to titles using index=titles.\n",
    "Use the .loc[] accessor of df to select the row with title 'Anne Hathaway', and print the result. These are the NMF features for the article about the actress Anne Hathaway.\n",
    "Repeat the last step for 'Denzel Washington' (another actor).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a pandas DataFrame: df\n",
    "df = pd.DataFrame(nmf_features, index=titles)\n",
    "\n",
    "# Print the row for 'Anne Hathaway'\n",
    "print(df.loc['Anne Hathaway'])\n",
    "\n",
    "# Print the row for 'Denzel Washington'\n",
    "print(df.loc['Denzel Washington'])\n",
    "\n",
    "<script.py> output:\n",
    "    0    0.003845\n",
    "    1    0.000000\n",
    "    2    0.000000\n",
    "    3    0.575711\n",
    "    4    0.000000\n",
    "    5    0.000000\n",
    "    Name: Anne Hathaway, dtype: float64\n",
    "    0    0.000000\n",
    "    1    0.005601\n",
    "    2    0.000000\n",
    "    3    0.422380\n",
    "    4    0.000000\n",
    "    5    0.000000\n",
    "    Name: Denzel Washington, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! Notice that for both actors, the NMF feature 3 has by far the highest value. This means that both articles are reconstructed using mainly the 3rd NMF component. In the next video, you'll see why: NMF components represent topics (for instance, acting!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### NMF reconstructs samples\n",
    "In this exercise, you'll check your understanding of how NMF reconstructs samples from its components using the NMF feature values. On the right are the components of an NMF model. If the NMF feature values of a sample are [2, 1], then which of the following is most likely to represent the original sample? A pen and paper will help here! You have to apply the same technique Ben used in the video to reconstruct the sample [0.1203 0.1764 0.3195 0.141].\n",
    "\n",
    "[[1.  0.5 0. ]\n",
    " \n",
    " [0.2 0.1 2.1]]\n",
    " \n",
    "### Possible Answers\n",
    "\n",
    "[2.2, 1.1, 2.1].  CORRECT ANSWER\n",
    "\n",
    "[0.5, 1.6, 3.1].\n",
    "\n",
    "[-4.0, 1.0, -2.0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### NMF learns topics of documents\n",
    "In the video, you learned when NMF is applied to documents, the components correspond to topics of documents, and the NMF features reconstruct the documents from the topics. Verify this for yourself for the NMF model that you built earlier using the Wikipedia articles. Previously, you saw that the 3rd NMF feature value was high for the articles about actors Anne Hathaway and Denzel Washington. In this exercise, identify the topic of the corresponding NMF component.\n",
    "\n",
    "The NMF model you built earlier is available as model, while words is a list of the words that label the columns of the word-frequency array.\n",
    "\n",
    "After you are done, take a moment to recognise the topic that the articles about Anne Hathaway and Denzel Washington have in common!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import pandas as pd.\n",
    "Create a DataFrame components_df from model.components_, setting columns=words so that columns are labeled by the words.\n",
    "Print components_df.shape to check the dimensions of the DataFrame.\n",
    "Use the .iloc[] accessor on the DataFrame components_df to select row 3. Assign the result to component.\n",
    "Call the .nlargest() method of component, and print the result. This gives the five words with the highest values for that component.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame: components_df\n",
    "components_df = pd.DataFrame(model.components_, columns=words)\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(components_df.shape)\n",
    "\n",
    "# Select row 3: component\n",
    "component = components_df.iloc[3]\n",
    "\n",
    "# Print result of nlargest\n",
    "print(component.nlargest())\n",
    "\n",
    "<script.py> output:\n",
    "    (6, 13125)\n",
    "    film       0.627877\n",
    "    award      0.253131\n",
    "    starred    0.245284\n",
    "    role       0.211451\n",
    "    actress    0.186398\n",
    "    Name: 3, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! Take a moment to recognise the topics that the articles about Anne Hathaway and Denzel Washington have in common!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Explore the LED digits dataset\n",
    "In the following exercises, you'll use NMF to decompose grayscale images into their commonly occurring patterns. Firstly, explore the image dataset and see how it is encoded as an array. You are given 100 images as a 2D array samples, where each row represents a single 13x8 image. The images in your dataset are pictures of a LED digital display.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import matplotlib.pyplot as plt.\n",
    "Select row 0 of samples and assign the result to digit. For example, to select column 2 of an array a, you could use a[:,2]. Remember that since samples is a NumPy array, you can't use the .loc[] or iloc[] accessors to select specific rows or columns.\n",
    "Print digit. This has been done for you. Notice that it is a 1D array of 0s and 1s.\n",
    "Use the .reshape() method of digit to get a 2D array with shape (13, 8). Assign the result to bitmap.\n",
    "Print bitmap, and notice that the 1s show the digit 7!\n",
    "Use the plt.imshow() function to display bitmap as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Select the 0th row: digit\n",
    "digit = samples[0,:]\n",
    "\n",
    "# Print digit\n",
    "print(digit)\n",
    "\n",
    "# Reshape digit to a 13x8 array: bitmap\n",
    "bitmap = digit.reshape(13,8)\n",
    "\n",
    "# Print bitmap\n",
    "print(bitmap)\n",
    "\n",
    "# Use plt.imshow to display bitmap\n",
    "plt.imshow(bitmap, cmap='gray', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "<script.py> output:\n",
    "    [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
    "     0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
    "     0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
    "     0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    "     0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "    [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "     [0. 0. 1. 1. 1. 1. 0. 0.]\n",
    "     [0. 0. 0. 0. 0. 0. 1. 0.]\n",
    "     [0. 0. 0. 0. 0. 0. 1. 0.]\n",
    "     [0. 0. 0. 0. 0. 0. 1. 0.]\n",
    "     [0. 0. 0. 0. 0. 0. 1. 0.]\n",
    "     [0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "     [0. 0. 0. 0. 0. 0. 1. 0.]\n",
    "     [0. 0. 0. 0. 0. 0. 1. 0.]\n",
    "     [0. 0. 0. 0. 0. 0. 1. 0.]\n",
    "     [0. 0. 0. 0. 0. 0. 1. 0.]\n",
    "     [0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "     [0. 0. 0. 0. 0. 0. 0. 0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent job! You'll explore this dataset further in the next exercise and see for yourself how NMF can learn the parts of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### NMF learns the parts of images\n",
    "Now use what you've learned about NMF to decompose the digits dataset. You are again given the digit images as a 2D array samples. This time, you are also provided with a function show_as_image() that displays the image encoded by any 1D array:\n",
    "\n",
    "def show_as_image(sample):\n",
    "    bitmap = sample.reshape((13, 8))\n",
    "    plt.figure()\n",
    "    plt.imshow(bitmap, cmap='gray', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "After you are done, take a moment to look through the plots and notice how NMF has expressed the digit as a sum of the components!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import NMF from sklearn.decomposition.\n",
    "Create an NMF instance called model with 7 components. (7 is the number of cells in an LED display).\n",
    "Apply the .fit_transform() method of model to samples. Assign the result to features.\n",
    "To each component of the model (accessed via model.components_), apply the show_as_image() function to that component inside the loop.\n",
    "Assign the row 0 of features to digit_features.\n",
    "Print digit_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NMF\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Create an NMF model: model\n",
    "model = NMF(n_components=7)\n",
    "\n",
    "# Apply fit_transform to samples: features\n",
    "features = model.fit_transform(samples)\n",
    "\n",
    "# Call show_as_image on each component\n",
    "for component in model.components_:\n",
    "    show_as_image(component)\n",
    "\n",
    "# Assign the 0th row of features: digit_features\n",
    "digit_features = features[0,:]\n",
    "\n",
    "# Print digit_features\n",
    "print(digit_features)\n",
    "\n",
    "<script.py> output:\n",
    "    [4.76823559e-01 0.00000000e+00 0.00000000e+00 5.90605054e-01\n",
    "     4.81559442e-01 0.00000000e+00 7.37557191e-16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! Take a moment to look through the plots and notice how NMF has expressed the digit as a sum of the components!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### PCA doesn't learn parts\n",
    "Unlike NMF, PCA doesn't learn the parts of things. Its components do not correspond to topics (in the case of documents) or to parts of images, when trained on images. Verify this for yourself by inspecting the components of a PCA model fit to the dataset of LED digit images from the previous exercise. The images are available as a 2D array samples. Also available is a modified version of the show_as_image() function which colors a pixel red if the value is negative.\n",
    "\n",
    "After submitting the answer, notice that the components of PCA do not represent meaningful parts of images of LED digits!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import PCA from sklearn.decomposition.\n",
    "Create a PCA instance called model with 7 components.\n",
    "Apply the .fit_transform() method of model to samples. Assign the result to features.\n",
    "To each component of the model (accessed via model.components_), apply the show_as_image() function to that component inside the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a PCA instance: model\n",
    "model = PCA(7)\n",
    "\n",
    "# Apply fit_transform to samples: features\n",
    "features = model.fit_transform(samples)\n",
    "\n",
    "# Call show_as_image on each component\n",
    "for component in model.components_:\n",
    "    show_as_image(component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! Notice that the components of PCA do not represent meaningful parts of images of LED digits!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Which articles are similar to 'Cristiano Ronaldo'?\n",
    "In the video, you learned how to use NMF features and the cosine similarity to find similar articles. Apply this to your NMF model for popular Wikipedia articles, by finding the articles most similar to the article about the footballer Cristiano Ronaldo. The NMF features you obtained earlier are available as nmf_features, while titles is a list of the article titles.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import normalize from sklearn.preprocessing.\n",
    "Apply the normalize() function to nmf_features. Store the result as norm_features.\n",
    "Create a DataFrame df from norm_features, using titles as an index.\n",
    "Use the .loc[] accessor of df to select the row of 'Cristiano Ronaldo'. Assign the result to article.\n",
    "Apply the .dot() method of df to article to calculate the cosine similarity of every row with article.\n",
    "Print the result of the .nlargest() method of similarities to display the most similiar articles. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_features \n",
    "[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "        0.00000000e+00, 4.40465322e-01],\n",
    "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "        0.00000000e+00, 5.66604756e-01],\n",
    "       [3.82058457e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "        0.00000000e+00, 3.98646427e-01],\n",
    "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "        0.00000000e+00, 3.81739753e-01],\n",
    "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "        0.00000000e+00, 4.85517119e-01],\n",
    "       [1.29290459e-02, 1.37889184e-02, 7.76313733e-03, 3.34487322e-02,\n",
    "        0.00000000e+00, 3.34521818e-01],\n",
    "       [0.00000000e+00, 0.00000000e+00, 2.06738655e-02, 0.00000000e+00,\n",
    "        6.04486283e-03, 3.59061038e-01],\n",
    "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "        0.00000000e+00, 4.90976703e-01],\n",
    "       [1.54274156e-02, 1.42817184e-02, 3.76628748e-03, 2.37111817e-02,\n",
    "        2.62619893e-02, 4.80774318e-01],\n",
    "       [1.11738298e-02, 3.13676816e-02, 3.09480486e-02, 6.57000345e-02,\n",
    "        1.96677390e-02, 3.38288648e-01],\n",
    "       [0.00000000e+00, 0.00000000e+00, 5.30710112e-01, 0.00000000e+00,\n",
    "        2.83679347e-02, 0.00000000e+00],\n",
    "       [0.00000000e+00, 0.00000000e+00, 3.56503042e-01, 0.00000000e+00,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [1.20127255e-02, 6.50033756e-03, 3.12239769e-01, 6.09770818e-02,\n",
    "        1.13861318e-02, 1.92602102e-02],\n",
    "       [3.93485615e-03, 6.24432234e-03, 3.42367241e-01, 1.10768934e-02,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [4.63821398e-03, 0.00000000e+00, 4.34907414e-01, 0.00000000e+00,\n",
    "        3.84274924e-02, 3.08133140e-03],\n",
    "       [0.00000000e+00, 0.00000000e+00, 4.83280609e-01, 0.00000000e+00,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [5.65016594e-03, 1.83532464e-02, 3.76526384e-01, 3.25460935e-02,\n",
    "        0.00000000e+00, 1.13334438e-02],\n",
    "       [0.00000000e+00, 0.00000000e+00, 4.80905320e-01, 0.00000000e+00,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [0.00000000e+00, 9.01849274e-03, 5.50998244e-01, 0.00000000e+00,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [0.00000000e+00, 0.00000000e+00, 4.65961434e-01, 0.00000000e+00,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [0.00000000e+00, 1.14078934e-02, 2.08651998e-02, 5.17767327e-01,\n",
    "        5.81408435e-02, 1.37853805e-02],\n",
    "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.10475273e-01,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [0.00000000e+00, 5.60094760e-03, 0.00000000e+00, 4.22379854e-01,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.36751253e-01,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.98092036e-01,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [9.88394018e-02, 8.60029454e-02, 3.91028856e-03, 3.81017532e-01,\n",
    "        4.39239942e-04, 5.22151481e-03],\n",
    "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.72169888e-01,\n",
    "        0.00000000e+00, 7.13541985e-03],\n",
    "       [1.31468715e-02, 1.04851581e-02, 0.00000000e+00, 4.68906049e-01,\n",
    "        0.00000000e+00, 1.16309971e-02],\n",
    "       [3.84548688e-03, 0.00000000e+00, 0.00000000e+00, 5.75710557e-01,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [2.25244164e-03, 1.38734017e-03, 0.00000000e+00, 5.27945778e-01,\n",
    "        1.20264671e-02, 1.49483895e-02],\n",
    "       [0.00000000e+00, 4.07541038e-01, 1.85711419e-03, 0.00000000e+00,\n",
    "        2.96610497e-03, 4.52342305e-04],\n",
    "       [1.53421227e-03, 6.08162380e-01, 5.22269328e-04, 6.24853541e-03,\n",
    "        1.18444733e-03, 4.40074955e-04],\n",
    "       [5.38819366e-03, 2.65012410e-01, 5.38501825e-04, 1.86925929e-02,\n",
    "        6.38651189e-03, 2.90104872e-03],\n",
    "       [0.00000000e+00, 6.44904602e-01, 0.00000000e+00, 0.00000000e+00,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [0.00000000e+00, 6.08896305e-01, 0.00000000e+00, 0.00000000e+00,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [0.00000000e+00, 3.43679231e-01, 0.00000000e+00, 0.00000000e+00,\n",
    "        3.97794829e-03, 0.00000000e+00],\n",
    "       [6.10508849e-03, 3.15307295e-01, 1.54877295e-02, 0.00000000e+00,\n",
    "        5.06244563e-03, 4.74335450e-03],\n",
    "       [6.47373328e-03, 2.13324818e-01, 9.49479174e-03, 4.56981207e-02,\n",
    "        1.71914481e-02, 9.52063620e-03],\n",
    "       [7.99147234e-03, 4.67586974e-01, 0.00000000e+00, 2.43425413e-02,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [0.00000000e+00, 6.42808850e-01, 0.00000000e+00, 2.35855413e-03,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "        4.77080113e-01, 0.00000000e+00],\n",
    "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "        4.94253212e-01, 0.00000000e+00],\n",
    "       [0.00000000e+00, 2.99063787e-04, 2.14484813e-03, 0.00000000e+00,\n",
    "        3.81776318e-01, 5.83780479e-03],\n",
    "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.64692771e-03,\n",
    "        5.42238170e-01, 0.00000000e+00],\n",
    "       [1.78059654e-03, 7.84399946e-04, 1.41625538e-02, 4.59813501e-04,\n",
    "        4.24299848e-01, 0.00000000e+00],\n",
    "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "        5.11388821e-01, 0.00000000e+00],\n",
    "       [0.00000000e+00, 0.00000000e+00, 3.28381076e-03, 0.00000000e+00,\n",
    "        3.72884543e-01, 0.00000000e+00],\n",
    "       [0.00000000e+00, 2.62079735e-04, 3.61098295e-02, 2.32336069e-04,\n",
    "        2.30509332e-01, 0.00000000e+00],\n",
    "       [1.12517699e-02, 2.12323850e-03, 1.60969841e-02, 1.02484866e-02,\n",
    "        3.25459591e-01, 3.75880596e-02],\n",
    "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "        4.18955707e-01, 3.57698689e-04],\n",
    "       [3.08373460e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [3.68181576e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [3.97953206e-01, 2.81698167e-02, 3.67005937e-03, 1.70066802e-02,\n",
    "        1.95966668e-03, 2.11644501e-02],\n",
    "       [3.75802488e-01, 2.07517079e-03, 0.00000000e+00, 3.72154373e-02,\n",
    "        0.00000000e+00, 5.85927894e-03],\n",
    "       [4.38037394e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [4.57890626e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "        0.00000000e+00, 0.00000000e+00],\n",
    "       [2.75483006e-01, 4.46948936e-03, 0.00000000e+00, 5.29655484e-02,\n",
    "        0.00000000e+00, 1.90997682e-02],\n",
    "       [4.45203267e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "        5.48695813e-03, 0.00000000e+00],\n",
    "       [2.92746533e-01, 1.33662475e-02, 1.14261498e-02, 1.05200030e-02,\n",
    "        1.87695369e-01, 9.23965223e-03],\n",
    "       [3.78274425e-01, 1.43967752e-02, 0.00000000e+00, 9.85239494e-02,\n",
    "        1.35899666e-02, 0.00000000e+00]]\n",
    "\n",
    "titles\n",
    "['HTTP 404',\n",
    " 'Alexa Internet',\n",
    " 'Internet Explorer',\n",
    " 'HTTP cookie',\n",
    " 'Google Search',\n",
    " 'Tumblr',\n",
    " 'Hypertext Transfer Protocol',\n",
    " 'Social search',\n",
    " 'Firefox',\n",
    " 'LinkedIn',\n",
    " 'Global warming',\n",
    " 'Nationally Appropriate Mitigation Action',\n",
    " 'Nigel Lawson',\n",
    " 'Connie Hedegaard',\n",
    " 'Climate change',\n",
    " 'Kyoto Protocol',\n",
    " '350.org',\n",
    " 'Greenhouse gas emissions by the United States',\n",
    " '2010 United Nations Climate Change Conference',\n",
    " '2007 United Nations Climate Change Conference',\n",
    " 'Angelina Jolie',\n",
    " 'Michael Fassbender',\n",
    " 'Denzel Washington',\n",
    " 'Catherine Zeta-Jones',\n",
    " 'Jessica Biel',\n",
    " 'Russell Crowe',\n",
    " 'Mila Kunis',\n",
    " 'Dakota Fanning',\n",
    " 'Anne Hathaway',\n",
    " 'Jennifer Aniston',\n",
    " 'France national football team',\n",
    " 'Cristiano Ronaldo',\n",
    " 'Arsenal F.C.',\n",
    " 'Radamel Falcao',\n",
    " 'Zlatan Ibrahimovi',\n",
    " 'Colombia national football team',\n",
    " '2014 FIFA World Cup qualification',\n",
    " 'Football',\n",
    " 'Neymar',\n",
    " 'Franck Ribry',\n",
    " 'Tonsillitis',\n",
    " 'Hepatitis B',\n",
    " 'Doxycycline',\n",
    " 'Leukemia',\n",
    " 'Gout',\n",
    " 'Hepatitis C',\n",
    " 'Prednisone',\n",
    " 'Fever',\n",
    " 'Gabapentin',\n",
    " 'Lymphoma',\n",
    " 'Chad Kroeger',\n",
    " 'Nate Ruess',\n",
    " 'The Wanted',\n",
    " 'Stevie Nicks',\n",
    " 'Arctic Monkeys',\n",
    " 'Black Sabbath',\n",
    " 'Skrillex',\n",
    " 'Red Hot Chili Peppers',\n",
    " 'Sepsis',\n",
    " 'Adam Levine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Normalize the NMF features: norm_features\n",
    "norm_features = normalize(nmf_features)\n",
    "\n",
    "# Create a DataFrame: df\n",
    "df = pd.DataFrame(norm_features, index=titles)\n",
    "\n",
    "# Select the row corresponding to 'Cristiano Ronaldo': article\n",
    "article = df.loc['Cristiano Ronaldo']\n",
    "\n",
    "# Compute the dot products: similarities\n",
    "similarities = df.dot(article)\n",
    "\n",
    "# Display those with the largest cosine similarity\n",
    "print(similarities.nlargest())\n",
    "\n",
    "<script.py> output:\n",
    "    Cristiano Ronaldo                1.000000\n",
    "    Franck Ribry                    0.999972\n",
    "    Radamel Falcao                   0.999942\n",
    "    Zlatan Ibrahimovi               0.999942\n",
    "    France national football team    0.999923\n",
    "    dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work - although you may need to know a little about football (or soccer, depending on where you're from!) to be able to evaluate for yourself the quality of the computed similarities!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Recommend musical artists part I\n",
    "In this exercise and the next, you'll use what you've learned about NMF to recommend popular music artists! You are given a sparse array artists whose rows correspond to artists and whose columns correspond to users. The entries give the number of times each artist was listened to by each user.\n",
    "\n",
    "In this exercise, build a pipeline and transform the array into normalized NMF features. The first step in the pipeline, MaxAbsScaler, transforms the data so that all users have the same influence on the model, regardless of how many different artists they've listened to. In the next exercise, you'll use the resulting normalized NMF features for recommendation!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Import:\n",
    "NMF from sklearn.decomposition.\n",
    "Normalizer and MaxAbsScaler from sklearn.preprocessing.\n",
    "make_pipeline from sklearn.pipeline.\n",
    "Create an instance of MaxAbsScaler called scaler.\n",
    "Create an NMF instance with 20 components called nmf.\n",
    "Create an instance of Normalizer called normalizer.\n",
    "Create a pipeline called pipeline that chains together scaler, nmf, and normalizer.\n",
    "Apply the .fit_transform() method of pipeline to artists. Assign the result to norm_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import Normalizer, MaxAbsScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a MaxAbsScaler: scaler\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "# Create an NMF model: nmf\n",
    "nmf = NMF(n_components=20)\n",
    "\n",
    "# Create a Normalizer: normalizer\n",
    "normalizer = Normalizer()\n",
    "\n",
    "# Create a pipeline: pipeline\n",
    "pipeline = make_pipeline(scaler, nmf, normalizer)\n",
    "\n",
    "# Apply fit_transform to artists: norm_features\n",
    "norm_features = pipeline.fit_transform(artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent work - now that you've computed the normalized NMF features, you'll use them in the next exercise to recommend musical artists!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "### Recommend musical artists part II\n",
    "Suppose you were a big fan of Bruce Springsteen - which other musicial artists might you like? Use your NMF features from the previous exercise and the cosine similarity to find similar musical artists. A solution to the previous exercise has been run, so norm_features is an array containing the normalized NMF features as rows. The names of the musical artists are available as the list artist_names.\n",
    "\n",
    "### Instructions\n",
    "Import pandas as pd.\n",
    "Create a DataFrame df from norm_features, using artist_names as an index.\n",
    "Use the .loc[] accessor of df to select the row of 'Bruce Springsteen'. Assign the result to artist.\n",
    "Apply the .dot() method of df to artist to calculate the dot product of every row with artist. Save the result as similarities.\n",
    "Print the result of the .nlargest() method of similarities to display the artists most similar to 'Bruce Springsteen'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame: df\n",
    "df = pd.DataFrame(norm_features,index = artist_names)\n",
    "\n",
    "# Select row of 'Bruce Springsteen': artist\n",
    "artist = df.loc['Bruce Springsteen']\n",
    "\n",
    "# Compute cosine similarities: similarities\n",
    "similarities = df.dot(artist)\n",
    "\n",
    "# Display those with highest cosine similarity\n",
    "print(similarities.nlargest('Bruce Springsteen'))\n",
    "\n",
    "<script.py> output:\n",
    "    Bruce Springsteen    1.000000\n",
    "    Neil Young           0.955896\n",
    "    Van Morrison         0.872452\n",
    "    Leonard Cohen        0.864763\n",
    "    Bob Dylan            0.859047\n",
    "    dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
